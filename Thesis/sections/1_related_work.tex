\chapter{Related Work}
\label{sec:related_work}

\paragraph{Human Pose Estimation}

To detect errors in HPE the methods of capturing the human pose from different modalities are essential. Multiple different human pose estimators have been developed using different modalities and focussing on different parts of the body. For example, OpenPose has developed a general human pose estimator\cite{OpenPosePose},  a hand pose estimator\cite{OpenPoseHand} and an estimator that is capable of detecting multiple people\cite{OpenPoseMulti}. Z. Cao et al. achieve this by using solely RGB data.

A method that uses RGB data in combination with errors for estimating the correct pose, is proposed by Joao Carreira et al.\cite{IterativeErrorFeedback}. In their paper, the authors extract the features of both input and output spaces. This enables Joao Carreira et al. to develop a self-correcting model using Iterative Error Feedback. 

Other methods use point clouds which are extracted from depth data. Point clouds are a representation of depth data which represents the environment using points. is commonly used in autonomous driving to represent the real world more accurately and to describe complex objects in the environment. However, conventional feature extraction using CNNs proves difficult to apply since most point clouds are not ordered and not dense so locality cannot be ensured. PointCNN, proposed by Yangyan Li et al.\cite{li2018pointcnn}, combats this problem by learning an $\mathcal{X}$-Transformation to then extract the features using a generalised CNN.

% Additionally, RGB in addition with depth data is used to estimate human pose data, for example with , which was proposed by proposed by D. Pascual-Hern√°ndez et al.\cite{PASCUALHERNANDEZ2022102225}.

\paragraph{Datasets}

There are different datasets encompassing different environments and modalities. The KITTI dataset is captured using LIDaR cameras and contains both depth and RGB data\cite{Geiger2012CVPR}. One of the largest datasets specifically for HPE and its applications is Human3.6M\cite{h36m_pami}. Human3.6M is a large-scale dataset containing RGB, Depth and Pose information.

\paragraph{Action Recognition}

One of the uses of HPE is action recognition. Action recognition is the extraction of pre-defined actions from different modalities. 

To use different modalities in combination Seddik et al. compare different fusion methods for action recognition\cite{Seddik2017}. After detecting the features for each of the modalities, RGB data, Depth data and Pose data, they fuse the features using different methods. 