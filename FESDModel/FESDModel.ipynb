{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FESDModel\n",
    "\n",
    "FESD - Fault estimation for skeleton detection - is a suite that aims at finding faults in joints of skeletons, which are detected by human pose estimatiors.\n",
    "\n",
    "FESDData is the sister project to this notebook, which aims at recording depth and rgb data, as well as populating the data with human poses from variing human pose estimators.\n",
    "\n",
    "Furthermore, FESTData augments all data based on joint confidence.\n",
    "\n",
    "FFESDModel aims to develop and evaluate a model based on the faulty and augmented joint data as well as RGBD data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "\n",
    "We need a range of libraries which are imported here. We also define some constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num cuda GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "\n",
    "from data import FESDDataset\n",
    "from data import Frame, AugmentationParams\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "\n",
    "from model import RD3D\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils import AvgMeter, clip_gradient, get_scheduler\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Num cuda GPUs: {num_gpus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECORDING_DIR = Path('H:/Recordings/')\n",
    "CHECKPOINT_DIR = Path('checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "\n",
    "for file in os.listdir(recording_dir):\n",
    "  if (file.endswith('.json')):\n",
    "    with open(file=os.path.join(recording_dir, file), mode='r') as file:\n",
    "      data = json.load(file)\n",
    "      data['Cameras'][0]['FileName']\n",
    "      self.size += data['Frames']\n",
    "      self.frames_per_session = data['Frames']\n",
    "      self.recording_jsons.append(data)\n",
    "frame_path = recording_dir /  session['Cameras'][0]['FileName'] / id_2_name(frame_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Firstly we need to import all the recordings into the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(file=\"Exercises.json\", mode='r') as file:\n",
    "  exercises_json = json.load(file)['Exercises']\n",
    "\n",
    "with open(file=\"JointErrors.json\", mode='r') as file:\n",
    "  joint_error_json = json.load(file)\n",
    "\n",
    "with open(file=\"SkeletonErrors.json\", mode='r') as file:\n",
    "  skeleton_error_json = json.load(file)\n",
    "\n",
    "len(exercises_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recordings Found: 25\n",
      "Total Frames: 7500\n"
     ]
    }
   ],
   "source": [
    "batchsize = 50\n",
    "train_size = 352\n",
    "\n",
    "dataset = FESDDataset(RECORDING_DIR, train_size)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batchsize)\n",
    "# build dataloader\n",
    "n_data = len(train_loader.dataset)\n",
    "CE = torch.nn.BCEWithLogitsLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Missing Joints\n",
      "tensor([1, 1, 1, 1, 1], dtype=torch.int8)\n",
      "All Wrong Joints\n",
      "tensor([[ -1.4217, 167.1556,   0.2603],\n",
      "        [ -1.1519, 170.9957,   0.2511]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "dataset.randomize_augmentation_params = False\n",
    "dataset.reset_augmentation_params()\n",
    "rgb, depth, pose_2d, errors = dataset[0]\n",
    "dataset.frame.show()\n",
    "\n",
    "print(\"All Missing Joints\")\n",
    "print(errors[errors==1])\n",
    "\n",
    "print(\"All Wrong Joints\")\n",
    "print(pose_2d[errors==2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model\n",
    "\n",
    "The model proposed by RD3D is based on resnet50 so we copy a pretrained resnet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\FESD\\FESDModel\\env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "h:\\FESD\\FESDModel\\env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RD3D(\n",
      "  (resnet): I3DResNet(\n",
      "    (conv1): Conv3d(3, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=(1, 1, 1), ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck3d(\n",
      "        (conv1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck3d(\n",
      "        (conv1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck3d(\n",
      "        (conv1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck3d(\n",
      "        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck3d(\n",
      "        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck3d(\n",
      "        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck3d(\n",
      "        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck3d(\n",
      "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck3d(\n",
      "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck3d(\n",
      "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck3d(\n",
      "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck3d(\n",
      "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck3d(\n",
      "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck3d(\n",
      "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck3d(\n",
      "        (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck3d(\n",
      "        (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (unet): Unet3D(\n",
      "    (reductions0): Reduction3D(\n",
      "      (reduce): Sequential(\n",
      "        (0): BasicConv3d(\n",
      "          (conv_bn): Sequential(\n",
      "            (0): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (1): BasicConv3d(\n",
      "          (conv_bn): Sequential(\n",
      "            (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (2): BasicConv3d(\n",
      "          (conv_bn): Sequential(\n",
      "            (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (reductions1): Reduction3D(\n",
      "      (reduce): Sequential(\n",
      "        (0): BasicConv3d(\n",
      "          (conv_bn): Sequential(\n",
      "            (0): Conv3d(256, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (1): BasicConv3d(\n",
      "          (conv_bn): Sequential(\n",
      "            (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (2): BasicConv3d(\n",
      "          (conv_bn): Sequential(\n",
      "            (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (reductions2): Reduction3D(\n",
      "      (reduce): Sequential(\n",
      "        (0): BasicConv3d(\n",
      "          (conv_bn): Sequential(\n",
      "            (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (1): BasicConv3d(\n",
      "          (conv_bn): Sequential(\n",
      "            (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (2): BasicConv3d(\n",
      "          (conv_bn): Sequential(\n",
      "            (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (reductions3): Reduction3D(\n",
      "      (reduce): Sequential(\n",
      "        (0): BasicConv3d(\n",
      "          (conv_bn): Sequential(\n",
      "            (0): Conv3d(1024, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (1): BasicConv3d(\n",
      "          (conv_bn): Sequential(\n",
      "            (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (2): BasicConv3d(\n",
      "          (conv_bn): Sequential(\n",
      "            (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (reductions4): Reduction3D(\n",
      "      (reduce): Sequential(\n",
      "        (0): BasicConv3d(\n",
      "          (conv_bn): Sequential(\n",
      "            (0): Conv3d(2048, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (1): BasicConv3d(\n",
      "          (conv_bn): Sequential(\n",
      "            (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (2): BasicConv3d(\n",
      "          (conv_bn): Sequential(\n",
      "            (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (output_s): ThreeDDecoder(\n",
      "      (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      (conv_upsample1): BasicConv3d(\n",
      "        (conv_bn): Sequential(\n",
      "          (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv_upsample2): BasicConv3d(\n",
      "        (conv_bn): Sequential(\n",
      "          (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv_upsample3): BasicConv3d(\n",
      "        (conv_bn): Sequential(\n",
      "          (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv_upsample4): BasicConv3d(\n",
      "        (conv_bn): Sequential(\n",
      "          (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv_downsample2_1): BasicConv3d(\n",
      "        (conv_bn): Sequential(\n",
      "          (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\n",
      "          (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv_downsample1_1): BasicConv3d(\n",
      "        (conv_bn): Sequential(\n",
      "          (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\n",
      "          (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv_downsample1_2): BasicConv3d(\n",
      "        (conv_bn): Sequential(\n",
      "          (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\n",
      "          (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv_downsample0_1): BasicConv3d(\n",
      "        (conv_bn): Sequential(\n",
      "          (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\n",
      "          (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv_downsample0_2): BasicConv3d(\n",
      "        (conv_bn): Sequential(\n",
      "          (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\n",
      "          (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv_downsample0_3): BasicConv3d(\n",
      "        (conv_bn): Sequential(\n",
      "          (0): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\n",
      "          (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (conv_cat1): Sequential(\n",
      "        (0): BasicConv3d(\n",
      "          (conv_bn): Sequential(\n",
      "            (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (1): BasicConv3d(\n",
      "          (conv_bn): Sequential(\n",
      "            (0): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv_cat2): Sequential(\n",
      "        (0): BasicConv3d(\n",
      "          (conv_bn): Sequential(\n",
      "            (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (1): BasicConv3d(\n",
      "          (conv_bn): Sequential(\n",
      "            (0): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv_cat3): Sequential(\n",
      "        (0): BasicConv3d(\n",
      "          (conv_bn): Sequential(\n",
      "            (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (1): BasicConv3d(\n",
      "          (conv_bn): Sequential(\n",
      "            (0): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv_cat4): Sequential(\n",
      "        (0): BasicConv3d(\n",
      "          (conv_bn): Sequential(\n",
      "            (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (1): BasicConv3d(\n",
      "          (conv_bn): Sequential(\n",
      "            (0): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "            (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downt1): BasicConv3d(\n",
      "        (conv_bn): Sequential(\n",
      "          (0): Conv3d(32, 32, kernel_size=(10, 1, 1), stride=(1, 1, 1))\n",
      "          (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (downt2): BasicConv3d(\n",
      "        (conv_bn): Sequential(\n",
      "          (0): Conv3d(32, 32, kernel_size=(7, 1, 1), stride=(1, 1, 1))\n",
      "          (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (downt3): BasicConv3d(\n",
      "        (conv_bn): Sequential(\n",
      "          (0): Conv3d(32, 32, kernel_size=(5, 1, 1), stride=(1, 1, 1))\n",
      "          (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (downt4): BasicConv3d(\n",
      "        (conv_bn): Sequential(\n",
      "          (0): Conv3d(32, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
      "          (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (out): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv_bn): Sequential(\n",
      "            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv_bn): Sequential(\n",
      "            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (se3): CMA(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=320, out_features=20, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=20, out_features=320, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (se2): CMA(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=224, out_features=14, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=14, out_features=224, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (se1): CMA(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=160, out_features=10, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=10, out_features=160, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (se0): CMA(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=96, out_features=6, bias=False)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=6, out_features=96, bias=False)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "resnet = torchvision.models.resnet50(pretrained=True)\n",
    "\n",
    "model = RD3D(32, copy.deepcopy(resnet))\n",
    "print(model)\n",
    "\n",
    "model = nn.DataParallel(model).cuda()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "In the following we define the training function and train a network on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "def train(train_loader, model, optimizer, criterion, scheduler, epoch, epochs):\n",
    "    # multi-scale training  \n",
    "\n",
    "    #model.train()\n",
    "    loss_record = AvgMeter()\n",
    "    for i, pack in enumerate(tqdm(train_loader), start=1):\n",
    "        # optimizer.zero_grad()\n",
    "\n",
    "        # # RD3D\n",
    "        # rgb = frame.rgb\n",
    "        # depth = frame.depth\n",
    "\n",
    "        # images = torch.cat([rgb, depth], 2)\n",
    "\n",
    "        # # Seperate Network\n",
    "        # pose = frame.poses_2d\n",
    "\n",
    "        # gt = frame.errors\n",
    "        \n",
    "        \n",
    "\n",
    "    #     images = images.cuda()\n",
    "    #     gts = gts.cuda()\n",
    "    #     depths = depths.cuda()\n",
    "\n",
    "    #     # multi-scale training samples\n",
    "    #     trainsize = int(round(opt.trainsize * rate / 32) * 32)\n",
    "    #     if rate != 1:\n",
    "    #         images = F.upsample(images, size=(trainsize, trainsize), mode='bilinear', align_corners=True)\n",
    "    #         images = images.unsqueeze(2)\n",
    "    #         gts = F.upsample(gts, size=(trainsize, trainsize), mode='bilinear', align_corners=True)\n",
    "\n",
    "    #         depths = F.upsample(depths, size=(trainsize, trainsize), mode='bilinear', align_corners=True)\n",
    "    #         depths = depths.unsqueeze(2)\n",
    "    #         images = torch.cat([images, depths], 2)\n",
    "\n",
    "    #     if rate == 1:\n",
    "    #         images = images.unsqueeze(2)\n",
    "    #         depths = depths.unsqueeze(2)\n",
    "    #         images = torch.cat([images, depths], 2)\n",
    "\n",
    "    #     # forward\n",
    "    #     pred_s = model(images)\n",
    "    #     # TODO Calculate different loss based on the error label\n",
    "    #     loss = criterion(pred_s, gts)\n",
    "\n",
    "    #     loss.backward()\n",
    "    #     clip_gradient(optimizer, opt.clip)\n",
    "    #     optimizer.step()\n",
    "    #     scheduler.step()\n",
    "    #     if rate == 1:\n",
    "            \n",
    "    #         loss_record.update(loss.data, opt.batchsize)\n",
    "      \n",
    "        if i % 100 == 0 or i == len(train_loader) or True:\n",
    "            print('Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss: {:.4f}'.\n",
    "                        format(epoch, epochs, i, len(train_loader),\n",
    "                               loss_record.show()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch number\n",
    "epochs = 50\n",
    "# optimizer\n",
    "optim = 'adamW'\n",
    "# learning rate\n",
    "learning_rate = 0.000125\n",
    "# learning rate scheduler. can be step, poly or cosine\n",
    "lr_scheduler = 'cosine'\n",
    "# warmup epoch\n",
    "warmup_epoch = -1\n",
    "# warmup multiplier\n",
    "warmup_multiplier = 100\n",
    "# for step scheduler. where to decay lr, can be a list\n",
    "lr_decay_epochs = [120, 160, 200]\n",
    "# for step scheduler. step size to decay lr\n",
    "lr_decay_steps = 20 \n",
    "# for step scheduler. decay rate for learning rate\n",
    "lr_decay_rate = 0.1\n",
    "# weight decay\n",
    "weight_decay = 0.0001\n",
    "# momentum for SGD\n",
    "momentum = 0.9\n",
    "# gradient clipping margin\n",
    "clip = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if optim == 'adam':\n",
    "    optimizer = torch.optim.Adam(model.parameters(), learning_rate, weight_decay=weight_decay)\n",
    "elif optim == 'adamW':\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), learning_rate, weight_decay=weight_decay)\n",
    "elif optim == 'sdg':\n",
    "    optimizer = torch.optim.SGD(model.parameters(), learning_rate / 10.0 * batchsize, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "scheduler = get_scheduler(optimizer, len(train_loader), lr_scheduler, lr_decay_epochs, lr_decay_steps, lr_decay_rate, epochs, warmup_epoch, warmup_multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]h:\\FESD\\FESDModel\\env\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "h:\\FESD\\FESDModel\\env\\lib\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "  1%|          | 1/150 [00:28<1:10:09, 28.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [001/050], Step [0001/0150], Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 2/150 [00:56<1:09:17, 28.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [001/050], Step [0002/0150], Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/150 [01:24<1:09:23, 28.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [001/050], Step [0003/0150], Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/150 [01:54<1:10:21, 28.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [001/050], Step [0004/0150], Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 5/150 [02:23<1:09:25, 28.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [001/050], Step [0005/0150], Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 6/150 [02:51<1:08:31, 28.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [001/050], Step [0006/0150], Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 7/150 [03:20<1:08:47, 28.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [001/050], Step [0007/0150], Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 8/150 [03:49<1:08:28, 28.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [001/050], Step [0008/0150], Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 8/150 [03:54<1:09:20, 29.30s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m      3\u001b[0m     tic \u001b[39m=\u001b[39m time()\n\u001b[1;32m----> 4\u001b[0m     train(train_loader, model, optimizer, CE, scheduler, epoch, epochs)\n\u001b[0;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mepoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m, total time \u001b[39m\u001b[39m{\u001b[39;00mtime()\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39mtic\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, learning_rate \u001b[39m\u001b[39m{\u001b[39;00moptimizer\u001b[39m.\u001b[39mparam_groups[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m     \u001b[39mif\u001b[39;00m (epoch) \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m      8\u001b[0m         \u001b[39m# torch.save(model.state_dict(), os.path.join(opt.output_dir, f\"RD3D_{epoch}_ckpt.pth\"))\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[13], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, model, optimizer, criterion, scheduler, epoch, epochs)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(train_loader, model, optimizer, criterion, scheduler, epoch, epochs):\n\u001b[0;32m      3\u001b[0m     \u001b[39m# multi-scale training  \u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m     \u001b[39m#model.train()\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     loss_record \u001b[39m=\u001b[39m AvgMeter()\n\u001b[1;32m----> 7\u001b[0m     \u001b[39mfor\u001b[39;00m i, pack \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tqdm(train_loader), start\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m      8\u001b[0m         \u001b[39m# optimizer.zero_grad()\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m         \u001b[39m# # RD3D\u001b[39;00m\n\u001b[0;32m     11\u001b[0m         \u001b[39m# rgb = frame.rgb\u001b[39;00m\n\u001b[0;32m     12\u001b[0m         \u001b[39m# depth = frame.depth\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m         \u001b[39m# images = torch.cat([rgb, depth], 2)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m         \u001b[39m# # Seperate Network\u001b[39;00m\n\u001b[0;32m     17\u001b[0m         \u001b[39m# pose = frame.poses_2d\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m         \u001b[39m# gt = frame.errors\u001b[39;00m\n\u001b[0;32m     20\u001b[0m         \n\u001b[0;32m     21\u001b[0m         \n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m     \u001b[39m#     images = images.cuda()\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     \u001b[39m#     gts = gts.cuda()\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     \u001b[39m#     depths = depths.cuda()\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m     \u001b[39m#     # multi-scale training samples\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     \u001b[39m#     trainsize = int(round(opt.trainsize * rate / 32) * 32)\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     \u001b[39m#     if rate != 1:\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     \u001b[39m#         images = F.upsample(images, size=(trainsize, trainsize), mode='bilinear', align_corners=True)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     \u001b[39m#         images = images.unsqueeze(2)\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     \u001b[39m#         gts = F.upsample(gts, size=(trainsize, trainsize), mode='bilinear', align_corners=True)\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \n\u001b[0;32m     34\u001b[0m     \u001b[39m#         depths = F.upsample(depths, size=(trainsize, trainsize), mode='bilinear', align_corners=True)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[39m#         depths = depths.unsqueeze(2)\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     \u001b[39m#         images = torch.cat([images, depths], 2)\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m     \u001b[39m#     if rate == 1:\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     \u001b[39m#         images = images.unsqueeze(2)\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[39m#         depths = depths.unsqueeze(2)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[39m#         images = torch.cat([images, depths], 2)\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \n\u001b[0;32m     43\u001b[0m     \u001b[39m#     # forward\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[39m#     pred_s = model(images)\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     \u001b[39m#     # TODO Calculate different loss based on the error label\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     \u001b[39m#     loss = criterion(pred_s, gts)\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \n\u001b[0;32m     48\u001b[0m     \u001b[39m#     loss.backward()\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     \u001b[39m#     clip_gradient(optimizer, opt.clip)\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[39m#     optimizer.step()\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     \u001b[39m#     scheduler.step()\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     \u001b[39m#     if rate == 1:\u001b[39;00m\n\u001b[0;32m     53\u001b[0m             \n\u001b[0;32m     54\u001b[0m     \u001b[39m#         loss_record.update(loss.data, opt.batchsize)\u001b[39;00m\n\u001b[0;32m     56\u001b[0m         \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(train_loader) \u001b[39mor\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEpoch [\u001b[39m\u001b[39m{:03d}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{:03d}\u001b[39;00m\u001b[39m], Step [\u001b[39m\u001b[39m{:04d}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{:04d}\u001b[39;00m\u001b[39m], Loss: \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m     58\u001b[0m                         \u001b[39mformat\u001b[39m(epoch, epochs, i, \u001b[39mlen\u001b[39m(train_loader),\n\u001b[0;32m     59\u001b[0m                                loss_record\u001b[39m.\u001b[39mshow()))\n",
      "File \u001b[1;32mh:\\FESD\\FESDModel\\env\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mh:\\FESD\\FESDModel\\env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mh:\\FESD\\FESDModel\\env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mh:\\FESD\\FESDModel\\env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mh:\\FESD\\FESDModel\\env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mh:\\FESD\\FESDModel\\data\\dataset.py:66\u001b[0m, in \u001b[0;36mFESDDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     63\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maugmentation_params\u001b[39m.\u001b[39mRandomize()\n\u001b[0;32m     64\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maugmentation_params)\n\u001b[1;32m---> 66\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframe \u001b[39m=\u001b[39m load_frame(recording_dir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrecording_dir, session\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrecording_jsons[session], frame_id\u001b[39m=\u001b[39;49mindex, params\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maugmentation_params)\n\u001b[0;32m     68\u001b[0m rgb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_transform(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframe\u001b[39m.\u001b[39mrgb\u001b[39m.\u001b[39mcopy())\n\u001b[0;32m     69\u001b[0m depth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdepths_transform(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframe\u001b[39m.\u001b[39mdepth\u001b[39m.\u001b[39mcopy())\n",
      "File \u001b[1;32mh:\\FESD\\FESDModel\\data\\frame_loader.py:75\u001b[0m, in \u001b[0;36mload_frame\u001b[1;34m(recording_dir, session, frame_id, params)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_frame\u001b[39m(recording_dir: Path, session: json, frame_id: \u001b[39mint\u001b[39m, params: AugmentationParams \u001b[39m=\u001b[39m AugmentationParams()) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Frame:\n\u001b[0;32m     74\u001b[0m   frame_path \u001b[39m=\u001b[39m recording_dir \u001b[39m/\u001b[39m  session[\u001b[39m'\u001b[39m\u001b[39mCameras\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mFileName\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m/\u001b[39m id_2_name(frame_id)\n\u001b[1;32m---> 75\u001b[0m   frame_file \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mFileStorage(\u001b[39mstr\u001b[39;49m(frame_path), cv2\u001b[39m.\u001b[39;49mFileStorage_READ)\n\u001b[0;32m     76\u001b[0m   frame \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray( frame_file\u001b[39m.\u001b[39mgetNode(\u001b[39m'\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mmat()[:,:] )\n\u001b[0;32m     77\u001b[0m   rgb, depth \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msplit(frame, [\u001b[39m3\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# routine\n",
    "for epoch in range(1, epochs + 1):\n",
    "    tic = time()\n",
    "    train(train_loader, model, optimizer, CE, scheduler, epoch, epochs)\n",
    "    print(f'epoch {epoch}, total time {time() - tic:.2f}, learning_rate {optimizer.param_groups[0][\"lr\"]}')\n",
    "\n",
    "    if (epoch) % 10 == 0:\n",
    "        # torch.save(model.state_dict(), os.path.join(opt.output_dir, f\"RD3D_{epoch}_ckpt.pth\"))\n",
    "        print(f'epoch {epoch}, total time {time() - tic:.2f}, learning_rate {optimizer.param_groups[0][\"lr\"]}')\n",
    "\n",
    "        print(\"checkpoint saved {}!\".format(os.path.join(opt.output_dir, f\"{epoch}_ckpt.pth\")))\n",
    "# torch.save(model.state_dict(), os.path.join(CHECKPOINT_DIR, f\"last_ckpt.pth\"))\n",
    "print(f\"model saved {os.path.join(CHECKPOINT_DIR, f'last_ckpt.pth')}!\")\n",
    "checkpoint = os.path.join(opt.output_dir, f\"last_ckpt.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, pack in enumerate(train_loader, start=1):\n",
    "  print(pack)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "223e9e27cbc670f5c22c33ebc1577b54f1cca48f7f6b973b1c50992e7fee7cdc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
