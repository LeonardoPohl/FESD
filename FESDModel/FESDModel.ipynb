{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FESDModel\n",
    "\n",
    "FESD - Fault estimation for skeleton detection - is a suite that aims at finding faults in joints of skeletons, which are detected by human pose estimatiors.\n",
    "\n",
    "FESDData is the sister project to this notebook, which aims at recording depth and rgb data, as well as populating the data with human poses from variing human pose estimators.\n",
    "\n",
    "Furthermore, FESTData augments all data based on joint confidence.\n",
    "\n",
    "FFESDModel aims to develop and evaluate a model based on the faulty and augmented joint data as well as RGBD data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "\n",
    "We need a range of libraries which are imported here. We also define some constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num cuda GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "\n",
    "from data import FESDDataset\n",
    "from data import Frame, AugmentationParams\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import cv2\n",
    "\n",
    "from model import FESD, FESDv2, train, val, test\n",
    "import copy\n",
    "\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import EfficientNet_V2_M_Weights\n",
    "\n",
    "import datetime\n",
    "\n",
    "from utils import AvgMeter, clip_gradient, get_scheduler\n",
    "from utils.mode import Mode\n",
    "from utils import err2gt, gt2err\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "num_gpus = torch.cuda.device_count()\n",
    "is_cuda = torch.cuda.is_available()\n",
    "print(f\"Num cuda GPUs: {num_gpus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECORDING_DIR = Path('H:/Recordings/')\n",
    "CHECKPOINT_DIR = Path('checkpoints')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Firstly we need to import all the recordings into the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(file=\"Exercises.json\", mode='r') as file:\n",
    "  exercises_json = json.load(file)['Exercises']\n",
    "\n",
    "with open(file=\"JointErrors.json\", mode='r') as file:\n",
    "  joint_error_json = json.load(file)\n",
    "\n",
    "with open(file=\"SkeletonErrors.json\", mode='r') as file:\n",
    "  skeleton_error_json = json.load(file)\n",
    "\n",
    "len(exercises_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recordings Found: 17\n",
      "Total Frames: 510\n",
      "Recordings Found: 9\n",
      "Total Frames: 270\n"
     ]
    }
   ],
   "source": [
    "batchsize = 40\n",
    "im_size = 64\n",
    "\n",
    "test_exercises = ['E-0.01', 'E-1.01', 'E-2.01', 'E-3.01']\n",
    "\n",
    "use_v2 = True\n",
    "if use_v2:\n",
    "  model = FESDv2\n",
    "else:\n",
    "  model = FESD\n",
    "\n",
    "dataset_train = FESDDataset(RECORDING_DIR, im_size, test_exercises, randomize_augmentation_params=True, use_v2=use_v2)\n",
    "dataset_train.randomize_augmentation_params = True\n",
    "\n",
    "dataset_test = FESDDataset(RECORDING_DIR, im_size, test_exercises, test=True, use_v2=use_v2)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batchsize)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_names_all = [\"-\", \"Head\", \"Neck\", \"Torso\", \"Waist\", \"Left collar\", \"Left shoulder\", \"Left elbow\", \"Left wrist\", \"Left hand\", \"-\", \"Right collar\", \"Right shoulder\", \"Right elbow\", \"Right wrist\", \"Right hand\", \"-\", \"Left hip\", \"Left knee\", \"Left ankle\", \"-\", \"Right hip\", \"Right knee\", \"Right ankle\", \"-\"]\n",
    "joint_names = [i for i in joint_names_all if i != '-']\n",
    "\n",
    "body_halves = np.array([\"Upper Half\", \"Lower Half\"])\n",
    "limbs = np.array([\"Head\", \"Torso\", \"Left arm\", \"Right arm\", \"Left leg\", \"Right leg\"])\n",
    "\n",
    "upper_body_i = [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "lower_body_i = [3, 14, 15, 16, 17, 18, 19]\n",
    "\n",
    "torso_i     = [2, 3, 4, 9]\n",
    "head_i      = [0, 1]\n",
    "left_arm_i  = [5, 6, 7, 8]\n",
    "right_arm_i = [10, 11, 12, 13]\n",
    "left_leg_i  = [14, 15, 16]\n",
    "right_leg_i = [17, 18, 19]\n",
    "\n",
    "joint_errors = []\n",
    "for je in joint_error_json:\n",
    "  joint_errors.append(je[\"Name\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Build the model according to the chosen mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_modes = True\n",
    "mode = Mode.FULL_BODY\n",
    "\n",
    "if all_modes:\n",
    "  model_full_body = nn.DataParallel(model(Mode.FULL_BODY.get_num_layers()))\n",
    "  model_half_body = nn.DataParallel(model(Mode.HALF_BODY.get_num_layers()))\n",
    "  model_limbs     = nn.DataParallel(model(Mode.LIMBS.get_num_layers()))\n",
    "  model_joints    = nn.DataParallel(model(Mode.JOINTS.get_num_layers()))\n",
    "else:\n",
    "  model = nn.DataParallel(model(mode.get_num_layers()))\n",
    "\n",
    "if is_cuda:\n",
    "  if all_modes:\n",
    "    model_full_body = model_full_body.cuda()\n",
    "    model_half_body = model_half_body.cuda()\n",
    "    model_limbs     = model_limbs.cuda()\n",
    "    model_joints    = model_joints.cuda()\n",
    "  else:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model\n",
    "\n",
    "In the following we define the training function and train a network on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recordings Found: 17\n",
      "Total Frames: 510\n",
      "Recordings Found: 9\n",
      "Total Frames: 270\n",
      "Recordings Found: 17\n",
      "Total Frames: 510\n",
      "Recordings Found: 9\n",
      "Total Frames: 270\n",
      "Recordings Found: 17\n",
      "Total Frames: 510\n",
      "Recordings Found: 9\n",
      "Total Frames: 270\n",
      "Recordings Found: 17\n",
      "Total Frames: 510\n",
      "Recordings Found: 9\n",
      "Total Frames: 270\n"
     ]
    }
   ],
   "source": [
    "if (all_modes):\n",
    "  train_loader_full_body  = torch.utils.data.DataLoader(FESDDataset(RECORDING_DIR, im_size, test_exercises=test_exercises, mode=Mode.FULL_BODY, randomize_augmentation_params=True, use_v2=use_v2), batch_size=batchsize, shuffle=True)\n",
    "  test_loader_full_body   = torch.utils.data.DataLoader(FESDDataset(RECORDING_DIR, im_size, test_exercises=test_exercises, mode=Mode.FULL_BODY, test=True, use_v2=use_v2))\n",
    "  train_loader_half_body  = torch.utils.data.DataLoader(FESDDataset(RECORDING_DIR, im_size, test_exercises=test_exercises, mode=Mode.HALF_BODY, randomize_augmentation_params=True, use_v2=use_v2), batch_size=batchsize, shuffle=True)\n",
    "  test_loader_half_body   = torch.utils.data.DataLoader(FESDDataset(RECORDING_DIR, im_size, test_exercises=test_exercises, mode=Mode.HALF_BODY, test=True, use_v2=use_v2))\n",
    "  train_loader_limbs      = torch.utils.data.DataLoader(FESDDataset(RECORDING_DIR, im_size, test_exercises=test_exercises, mode=Mode.LIMBS, randomize_augmentation_params=True, use_v2=use_v2), batch_size=batchsize, shuffle=True)\n",
    "  test_loader_limbs       = torch.utils.data.DataLoader(FESDDataset(RECORDING_DIR, im_size, test_exercises=test_exercises, mode=Mode.LIMBS, test=True, use_v2=use_v2))\n",
    "  train_loader_joints     = torch.utils.data.DataLoader(FESDDataset(RECORDING_DIR, im_size, test_exercises=test_exercises, mode=Mode.JOINTS, randomize_augmentation_params=True, use_v2=use_v2), batch_size=batchsize, shuffle=True)\n",
    "  test_loader_joints      = torch.utils.data.DataLoader(FESDDataset(RECORDING_DIR, im_size, test_exercises=test_exercises, mode=Mode.JOINTS, test=True, use_v2=use_v2))\n",
    "\n",
    "else:\n",
    "  train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batchsize)\n",
    "  test_loader = torch.utils.data.DataLoader(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader_half_body:\n",
    "  merged, _, _ = i\n",
    "  print(merged.size())\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "torchrun --nproc_per_node=8 train.py \\\n",
    "--model $MODEL --batch-size 128 --lr 0.5 --lr-scheduler cosineannealinglr \\\n",
    "--lr-warmup-epochs 5 --lr-warmup-method linear --auto-augment ta_wide --epochs 600 --random-erase 0.1 \\\n",
    "--label-smoothing 0.1 --mixup-alpha 0.2 --cutmix-alpha 1.0 --weight-decay 0.00002 --norm-weight-decay 0.0 \\\n",
    "--train-crop-size $TRAIN_SIZE --model-ema --val-crop-size $EVAL_SIZE --val-resize-size $EVAL_SIZE \\\n",
    "--ra-sampler --ra-reps 4\n",
    "\"\"\"\n",
    "\n",
    "# epoch number\n",
    "epochs = 100\n",
    "# optimizer\n",
    "optim = 'adam'\n",
    "# learning rate\n",
    "learning_rate = 0.005\n",
    "# learning rate scheduler. can be step, poly or cosine\n",
    "lr_scheduler = 'cosine'\n",
    "# warmup epoch\n",
    "warmup_epoch = 0\n",
    "# warmup multiplier\n",
    "warmup_multiplier = 100\n",
    "# for step scheduler. where to decay lr, can be a list\n",
    "lr_decay_epochs = [120, 160, 200]\n",
    "# for step scheduler. step size to decay lr\n",
    "lr_decay_steps = 20 \n",
    "# for step scheduler. decay rate for learning rate\n",
    "lr_decay_rate = 0.01\n",
    "# weight decay\n",
    "weight_decay = 0.0001\n",
    "# momentum for SGD\n",
    "momentum = 0.9\n",
    "# gradient clipping margin\n",
    "clip = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = len(train_loader.dataset)\n",
    "CE = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "if is_cuda:\n",
    "    CE = CE.cuda()\n",
    "\n",
    "if all_modes:\n",
    "    if optim == 'adam':\n",
    "        optimizer_full_body = torch.optim.Adam(model_full_body.parameters(),    learning_rate, weight_decay=weight_decay)\n",
    "        optimizer_half_body = torch.optim.Adam(model_half_body.parameters(),    learning_rate, weight_decay=weight_decay)\n",
    "        optimizer_limbs     = torch.optim.Adam(model_limbs.parameters(),        learning_rate, weight_decay=weight_decay)\n",
    "        optimizer_joints    = torch.optim.Adam(model_joints.parameters(),       learning_rate, weight_decay=weight_decay)\n",
    "    elif optim == 'adamW':\n",
    "        optimizer_full_body = torch.optim.AdamW(model_full_body.parameters(),   learning_rate, weight_decay=weight_decay)\n",
    "        optimizer_half_body = torch.optim.AdamW(model_half_body.parameters(),   learning_rate, weight_decay=weight_decay)\n",
    "        optimizer_limbs     = torch.optim.AdamW(model_limbs.parameters(),       learning_rate, weight_decay=weight_decay)\n",
    "        optimizer_joints    = torch.optim.AdamW(model_joints.parameters(),      learning_rate, weight_decay=weight_decay)\n",
    "    elif optim == 'sdg':\n",
    "        optimizer_full_body = torch.optim.SGD(model_full_body.parameters(),     learning_rate / 10.0 * batchsize, momentum=momentum, weight_decay=weight_decay)\n",
    "        optimizer_half_body = torch.optim.SGD(model_half_body.parameters(),     learning_rate / 10.0 * batchsize, momentum=momentum, weight_decay=weight_decay)\n",
    "        optimizer_limbs     = torch.optim.SGD(model_limbs.parameters(),         learning_rate / 10.0 * batchsize, momentum=momentum, weight_decay=weight_decay)\n",
    "        optimizer_joints    = torch.optim.SGD(model_joints.parameters(),        learning_rate / 10.0 * batchsize, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "    scheduler_full_body     = get_scheduler(optimizer_full_body, len(train_loader_full_body), lr_scheduler, lr_decay_epochs, lr_decay_steps, lr_decay_rate, epochs, warmup_epoch,     warmup_multiplier)\n",
    "    scheduler_half_body     = get_scheduler(optimizer_half_body, len(train_loader_half_body), lr_scheduler, lr_decay_epochs, lr_decay_steps, lr_decay_rate, epochs, warmup_epoch, warmup_multiplier)\n",
    "    scheduler_limbs         = get_scheduler(optimizer_limbs, len(train_loader_limbs), lr_scheduler, lr_decay_epochs, lr_decay_steps, lr_decay_rate, epochs, warmup_epoch, warmup_multiplier)\n",
    "    scheduler_joints        = get_scheduler(optimizer_joints, len(train_loader_joints), lr_scheduler, lr_decay_epochs, lr_decay_steps, lr_decay_rate, epochs, warmup_epoch, warmup_multiplier)\n",
    "else:\n",
    "    if optim == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), learning_rate, weight_decay=weight_decay)\n",
    "    elif optim == 'adamW':\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), learning_rate, weight_decay=weight_decay)\n",
    "    elif optim == 'sdg':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), learning_rate / 10.0 * batchsize, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "    scheduler = get_scheduler(optimizer, len(train_loader), lr_scheduler, lr_decay_epochs, lr_decay_steps, lr_decay_rate, epochs, warmup_epoch, warmup_multiplier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_modes:\n",
    "    model_iterator = list(zip([Mode.FULL_BODY,          Mode.HALF_BODY,         Mode.LIMBS,         Mode.JOINTS], \n",
    "                              [model_full_body,         model_half_body,        model_limbs,        model_joints], \n",
    "                              [optimizer_full_body,     optimizer_half_body,    optimizer_limbs,    optimizer_joints], \n",
    "                              [scheduler_full_body,     scheduler_half_body,    scheduler_limbs,    scheduler_joints],\n",
    "                              [train_loader_full_body,  train_loader_half_body, train_loader_limbs, train_loader_joints], \n",
    "                              [test_loader_full_body,   test_loader_half_body,  test_loader_limbs,  test_loader_joints]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad3ee47d0e84aeea5e33e650b438d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---   1 ---\n",
      "Epoch (mode:  full body, lr: 0.005, loss: 0.77271, acc: 0.569, f1: 0.723, precision: 0.570, recall: 0.997, kappa: -0.004, time: 42.38s)\n",
      "Epoch (mode:  half body, lr: 0.005, loss: 0.40986, acc: 0.683, f1: 0.668, precision: 0.606, recall: 0.792, kappa: 0.205, time: 43.33s)\n",
      "Epoch (mode:      limbs, lr: 0.005, loss: 0.57193, acc: 0.768, f1: 0.861, precision: 0.793, recall: 0.956, kappa: 0.016, time: 46.03s)\n",
      "Epoch (mode:     joints, lr: 0.005, loss: 1.36795, acc: 0.795, f1: 0.594, precision: 0.783, recall: 0.818, kappa: 0.000, time: 53.24s)\n",
      "---   2 ---\n",
      "Epoch (mode:  full body, lr: 0.005, loss: 0.73370, acc: 0.573, f1: 0.725, precision: 0.573, recall: 1.000, kappa: 0.000, time: 43.54s)\n",
      "Epoch (mode:  half body, lr: 0.005, loss: 0.48778, acc: 0.673, f1: 0.670, precision: 0.601, recall: 0.812, kappa: 0.202, time: 44.07s)\n",
      "Epoch (mode:      limbs, lr: 0.005, loss: 0.53446, acc: 0.791, f1: 0.880, precision: 0.791, recall: 0.999, kappa: -0.001, time: 45.92s)\n",
      "Epoch (mode:     joints, lr: 0.005, loss: 0.93093, acc: 0.835, f1: 0.621, precision: 0.800, recall: 0.865, kappa: 0.000, time: 53.60s)\n",
      "---   3 ---\n",
      "Epoch (mode:  full body, lr: 0.005, loss: 0.74692, acc: 0.571, f1: 0.725, precision: 0.572, recall: 0.997, kappa: -0.004, time: 42.90s)\n",
      "Epoch (mode:  half body, lr: 0.005, loss: 0.40336, acc: 0.687, f1: 0.630, precision: 0.691, recall: 0.705, kappa: 0.194, time: 42.87s)\n",
      "Epoch (mode:      limbs, lr: 0.005, loss: 0.53007, acc: 0.790, f1: 0.880, precision: 0.790, recall: 1.000, kappa: 0.000, time: 45.10s)\n",
      "Epoch (mode:     joints, lr: 0.005, loss: 0.90941, acc: 0.836, f1: 0.622, precision: 0.801, recall: 0.865, kappa: 0.000, time: 53.44s)\n",
      "---   4 ---\n",
      "Epoch (mode:  full body, lr: 0.005, loss: 0.73810, acc: 0.571, f1: 0.723, precision: 0.571, recall: 1.000, kappa: 0.000, time: 44.07s)\n",
      "Epoch (mode:  half body, lr: 0.005, loss: 0.52604, acc: 0.652, f1: 0.481, precision: 0.636, recall: 0.566, kappa: 0.062, time: 44.06s)\n",
      "Epoch (mode:      limbs, lr: 0.005, loss: 0.52151, acc: 0.789, f1: 0.879, precision: 0.789, recall: 1.000, kappa: 0.000, time: 46.25s)\n",
      "Epoch (mode:     joints, lr: 0.005, loss: 0.93902, acc: 0.835, f1: 0.621, precision: 0.800, recall: 0.864, kappa: 0.000, time: 52.59s)\n",
      "---   5 ---\n",
      "Epoch (mode:  full body, lr: 0.005, loss: 0.70138, acc: 0.569, f1: 0.721, precision: 0.569, recall: 1.000, kappa: 0.000, time: 41.74s)\n",
      "Epoch (mode:  half body, lr: 0.005, loss: 0.68729, acc: 0.640, f1: 0.399, precision: 0.439, recall: 0.512, kappa: -0.003, time: 43.25s)\n",
      "Epoch (mode:      limbs, lr: 0.005, loss: 0.53447, acc: 0.790, f1: 0.879, precision: 0.790, recall: 1.000, kappa: 0.000, time: 45.25s)\n",
      "Epoch (mode:     joints, lr: 0.005, loss: nan, acc: 0.835, f1: 0.621, precision: 0.800, recall: 0.865, kappa: 0.000, time: 53.28s)\n",
      "---   6 ---\n",
      "Epoch (mode:  full body, lr: 0.005, loss: 0.76228, acc: 0.572, f1: 0.725, precision: 0.572, recall: 1.000, kappa: 0.000, time: 42.45s)\n",
      "Epoch (mode:  half body, lr: 0.005, loss: 0.65812, acc: 0.644, f1: 0.404, precision: 0.497, recall: 0.514, kappa: 0.002, time: 43.54s)\n",
      "Epoch (mode:      limbs, lr: 0.005, loss: 0.53213, acc: 0.791, f1: 0.880, precision: 0.791, recall: 1.000, kappa: 0.000, time: 44.99s)\n",
      "Epoch (mode:     joints, lr: 0.005, loss: 0.90915, acc: 0.836, f1: 0.622, precision: 0.801, recall: 0.865, kappa: 0.000, time: 52.73s)\n",
      "---   7 ---\n",
      "Epoch (mode:  full body, lr: 0.005, loss: 0.74661, acc: 0.571, f1: 0.725, precision: 0.571, recall: 1.000, kappa: 0.000, time: 41.79s)\n",
      "Epoch (mode:  half body, lr: 0.005, loss: 0.67641, acc: 0.638, f1: 0.389, precision: 0.381, recall: 0.507, kappa: -0.010, time: 42.66s)\n",
      "Epoch (mode:      limbs, lr: 0.005, loss: 0.50086, acc: 0.790, f1: 0.880, precision: 0.790, recall: 1.000, kappa: 0.000, time: 45.91s)\n",
      "Epoch (mode:     joints, lr: 0.005, loss: 0.90243, acc: 0.836, f1: 0.622, precision: 0.802, recall: 0.865, kappa: 0.000, time: 53.25s)\n",
      "---   8 ---\n",
      "Epoch (mode:  full body, lr: 0.005, loss: 0.74609, acc: 0.570, f1: 0.724, precision: 0.570, recall: 1.000, kappa: 0.000, time: 42.47s)\n",
      "Epoch (mode:  half body, lr: 0.005, loss: 0.66948, acc: 0.646, f1: 0.377, precision: 0.304, recall: 0.500, kappa: 0.000, time: 43.00s)\n",
      "Epoch (mode:      limbs, lr: 0.005, loss: 0.52442, acc: 0.789, f1: 0.879, precision: 0.789, recall: 1.000, kappa: 0.000, time: 45.11s)\n",
      "Epoch (mode:     joints, lr: 0.005, loss: 0.92173, acc: 0.836, f1: 0.622, precision: 0.801, recall: 0.865, kappa: 0.000, time: 52.29s)\n",
      "---   9 ---\n",
      "Epoch (mode:  full body, lr: 0.005, loss: 0.73304, acc: 0.570, f1: 0.723, precision: 0.570, recall: 1.000, kappa: 0.000, time: 42.19s)\n",
      "Epoch (mode:  half body, lr: 0.005, loss: 0.65534, acc: 0.645, f1: 0.375, precision: 0.302, recall: 0.500, kappa: 0.000, time: 42.66s)\n",
      "Epoch (mode:      limbs, lr: 0.005, loss: 0.50503, acc: 0.790, f1: 0.880, precision: 0.790, recall: 1.000, kappa: 0.000, time: 45.42s)\n",
      "Epoch (mode:     joints, lr: 0.005, loss: nan, acc: 0.835, f1: 0.621, precision: 0.800, recall: 0.864, kappa: 0.000, time: 52.91s)\n",
      "---  10 ---\n",
      "Epoch (mode:  full body, lr: 0.005, loss: 0.71475, acc: 0.571, f1: 0.724, precision: 0.571, recall: 1.000, kappa: 0.000, time: 42.47s)\n",
      "Epoch (mode:  half body, lr: 0.005, loss: 0.70445, acc: 0.648, f1: 0.376, precision: 0.304, recall: 0.500, kappa: 0.000, time: 42.66s)\n",
      "Epoch (mode:      limbs, lr: 0.005, loss: 0.53511, acc: 0.793, f1: 0.881, precision: 0.793, recall: 1.000, kappa: 0.000, time: 45.18s)\n",
      "Epoch (mode:     joints, lr: 0.005, loss: 0.90380, acc: 0.835, f1: 0.621, precision: 0.800, recall: 0.864, kappa: 0.000, time: 52.92s)\n",
      "---  11 ---\n",
      "Epoch (mode:  full body, lr: 0.005, loss: 0.73287, acc: 0.574, f1: 0.724, precision: 0.574, recall: 1.000, kappa: 0.000, time: 43.80s)\n",
      "Epoch (mode:  half body, lr: 0.005, loss: 0.66815, acc: 0.647, f1: 0.377, precision: 0.305, recall: 0.500, kappa: 0.000, time: 44.45s)\n",
      "Epoch (mode:      limbs, lr: 0.005, loss: 0.52068, acc: 0.792, f1: 0.881, precision: 0.792, recall: 1.000, kappa: 0.000, time: 46.40s)\n",
      "Epoch (mode:     joints, lr: 0.005, loss: 0.92775, acc: 0.836, f1: 0.621, precision: 0.800, recall: 0.865, kappa: 0.000, time: 53.53s)\n",
      "---  12 ---\n",
      "Epoch (mode:  full body, lr: 0.005, loss: 0.74306, acc: 0.571, f1: 0.725, precision: 0.571, recall: 1.000, kappa: 0.000, time: 43.12s)\n",
      "Epoch (mode:  half body, lr: 0.005, loss: 0.66334, acc: 0.646, f1: 0.377, precision: 0.303, recall: 0.500, kappa: 0.000, time: 43.64s)\n",
      "Epoch (mode:      limbs, lr: 0.005, loss: 0.52487, acc: 0.792, f1: 0.880, precision: 0.792, recall: 1.000, kappa: 0.000, time: 45.11s)\n",
      "Epoch (mode:     joints, lr: 0.005, loss: 0.92064, acc: 0.837, f1: 0.622, precision: 0.802, recall: 0.865, kappa: 0.000, time: 53.24s)\n",
      "---  13 ---\n",
      "Epoch (mode:  full body, lr: 0.005, loss: 0.75135, acc: 0.571, f1: 0.726, precision: 0.571, recall: 1.000, kappa: 0.000, time: 41.64s)\n",
      "Epoch (mode:  half body, lr: 0.005, loss: 0.65379, acc: 0.646, f1: 0.377, precision: 0.304, recall: 0.500, kappa: 0.000, time: 43.86s)\n",
      "Epoch (mode:      limbs, lr: 0.005, loss: 0.52792, acc: 0.792, f1: 0.881, precision: 0.792, recall: 1.000, kappa: 0.000, time: 45.32s)\n",
      "Epoch (mode:     joints, lr: 0.005, loss: 0.91531, acc: 0.837, f1: 0.622, precision: 0.802, recall: 0.865, kappa: 0.000, time: 53.43s)\n",
      "---  14 ---\n",
      "Epoch (mode:  full body, lr: 0.005, loss: 0.72269, acc: 0.569, f1: 0.722, precision: 0.569, recall: 1.000, kappa: 0.000, time: 41.84s)\n",
      "Epoch (mode:  half body, lr: 0.005, loss: 0.67704, acc: 0.646, f1: 0.374, precision: 0.302, recall: 0.500, kappa: 0.000, time: 43.06s)\n",
      "Epoch (mode:      limbs, lr: 0.005, loss: 0.50819, acc: 0.791, f1: 0.880, precision: 0.791, recall: 1.000, kappa: 0.000, time: 45.54s)\n",
      "Epoch (mode:     joints, lr: 0.005, loss: 0.93117, acc: 0.835, f1: 0.622, precision: 0.800, recall: 0.865, kappa: 0.000, time: 52.12s)\n",
      "---  15 ---\n",
      "Epoch (mode:  full body, lr: 0.005, loss: 0.74275, acc: 0.571, f1: 0.724, precision: 0.571, recall: 1.000, kappa: 0.000, time: 42.94s)\n",
      "Epoch (mode:  half body, lr: 0.005, loss: 0.63726, acc: 0.645, f1: 0.380, precision: 0.322, recall: 0.503, kappa: 0.002, time: 43.31s)\n",
      "Epoch (mode:      limbs, lr: 0.005, loss: 0.55912, acc: 0.792, f1: 0.881, precision: 0.792, recall: 1.000, kappa: 0.000, time: 45.46s)\n",
      "Epoch (mode:     joints, lr: 0.005, loss: 0.91172, acc: 0.836, f1: 0.622, precision: 0.801, recall: 0.865, kappa: 0.000, time: 52.94s)\n",
      "---  16 ---\n",
      "Epoch (mode:  full body, lr: 0.005, loss: 0.73936, acc: 0.572, f1: 0.726, precision: 0.572, recall: 1.000, kappa: 0.000, time: 42.14s)\n",
      "Epoch (mode:  half body, lr: 0.005, loss: 0.65925, acc: 0.644, f1: 0.376, precision: 0.303, recall: 0.500, kappa: 0.000, time: 42.42s)\n",
      "Epoch (mode:      limbs, lr: 0.005, loss: 0.51593, acc: 0.791, f1: 0.881, precision: 0.791, recall: 1.000, kappa: 0.000, time: 44.48s)\n",
      "Epoch (mode:     joints, lr: 0.005, loss: 0.91248, acc: 0.835, f1: 0.622, precision: 0.800, recall: 0.865, kappa: 0.000, time: 52.46s)\n",
      "---  17 ---\n",
      "Epoch (mode:  full body, lr: 0.005, loss: 0.75994, acc: 0.568, f1: 0.722, precision: 0.568, recall: 1.000, kappa: 0.000, time: 42.45s)\n",
      "Epoch (mode:  half body, lr: 0.005, loss: 0.67080, acc: 0.646, f1: 0.377, precision: 0.304, recall: 0.500, kappa: 0.000, time: 43.47s)\n",
      "Epoch (mode:      limbs, lr: 0.005, loss: 0.52202, acc: 0.791, f1: 0.881, precision: 0.791, recall: 1.000, kappa: 0.000, time: 45.53s)\n",
      "Epoch (mode:     joints, lr: 0.005, loss: 0.90594, acc: 0.835, f1: 0.621, precision: 0.800, recall: 0.865, kappa: 0.000, time: 53.44s)\n",
      "---  18 ---\n",
      "Epoch (mode:  full body, lr: 0.004, loss: 0.78932, acc: 0.572, f1: 0.724, precision: 0.572, recall: 1.000, kappa: 0.000, time: 44.23s)\n",
      "Epoch (mode:  half body, lr: 0.004, loss: 0.68439, acc: 0.647, f1: 0.377, precision: 0.305, recall: 0.500, kappa: 0.000, time: 43.87s)\n",
      "Epoch (mode:      limbs, lr: 0.004, loss: 0.51055, acc: 0.789, f1: 0.879, precision: 0.789, recall: 1.000, kappa: 0.000, time: 45.70s)\n",
      "Epoch (mode:     joints, lr: 0.005, loss: 0.93010, acc: 0.835, f1: 0.621, precision: 0.800, recall: 0.864, kappa: 0.000, time: 54.76s)\n",
      "---  19 ---\n",
      "Epoch (mode:  full body, lr: 0.004, loss: 0.76168, acc: 0.572, f1: 0.724, precision: 0.572, recall: 1.000, kappa: 0.000, time: 43.15s)\n",
      "Epoch (mode:  half body, lr: 0.004, loss: 0.65689, acc: 0.646, f1: 0.377, precision: 0.304, recall: 0.500, kappa: 0.000, time: 44.04s)\n",
      "Epoch (mode:      limbs, lr: 0.004, loss: 0.51320, acc: 0.789, f1: 0.880, precision: 0.789, recall: 1.000, kappa: 0.000, time: 45.35s)\n",
      "Epoch (mode:     joints, lr: 0.005, loss: 0.88871, acc: 0.834, f1: 0.621, precision: 0.799, recall: 0.864, kappa: 0.000, time: 53.63s)\n",
      "---  20 ---\n",
      "Epoch (mode:  full body, lr: 0.004, loss: 0.70371, acc: 0.569, f1: 0.721, precision: 0.569, recall: 1.000, kappa: 0.000, time: 42.01s)\n",
      "Epoch (mode:  half body, lr: 0.004, loss: 0.66305, acc: 0.646, f1: 0.377, precision: 0.304, recall: 0.500, kappa: 0.000, time: 42.57s)\n",
      "Epoch (mode:      limbs, lr: 0.004, loss: 0.53290, acc: 0.790, f1: 0.880, precision: 0.790, recall: 1.000, kappa: 0.000, time: 44.81s)\n",
      "Epoch (mode:     joints, lr: 0.005, loss: 0.92449, acc: 0.836, f1: 0.622, precision: 0.801, recall: 0.865, kappa: 0.000, time: 53.24s)\n",
      "---  21 ---\n",
      "Epoch (mode:  full body, lr: 0.004, loss: 0.75284, acc: 0.572, f1: 0.724, precision: 0.573, recall: 0.996, kappa: 0.003, time: 42.72s)\n",
      "Epoch (mode:  half body, lr: 0.004, loss: 0.66776, acc: 0.646, f1: 0.376, precision: 0.304, recall: 0.500, kappa: 0.000, time: 43.48s)\n",
      "Epoch (mode:      limbs, lr: 0.004, loss: 0.52372, acc: 0.792, f1: 0.881, precision: 0.792, recall: 1.000, kappa: 0.000, time: 45.86s)\n",
      "Epoch (mode:     joints, lr: 0.004, loss: nan, acc: 0.835, f1: 0.621, precision: 0.800, recall: 0.864, kappa: 0.000, time: 53.54s)\n",
      "---  22 ---\n",
      "Epoch (mode:  full body, lr: 0.004, loss: 0.75379, acc: 0.571, f1: 0.725, precision: 0.571, recall: 1.000, kappa: 0.000, time: 42.19s)\n",
      "Epoch (mode:  half body, lr: 0.004, loss: 0.66999, acc: 0.648, f1: 0.378, precision: 0.305, recall: 0.500, kappa: 0.000, time: 43.26s)\n",
      "Epoch (mode:      limbs, lr: 0.004, loss: 0.52621, acc: 0.790, f1: 0.880, precision: 0.790, recall: 1.000, kappa: 0.000, time: 44.88s)\n",
      "Epoch (mode:     joints, lr: 0.004, loss: 0.91871, acc: 0.834, f1: 0.621, precision: 0.799, recall: 0.864, kappa: 0.000, time: 53.19s)\n",
      "---  23 ---\n",
      "Epoch (mode:  full body, lr: 0.004, loss: 0.76630, acc: 0.572, f1: 0.724, precision: 0.572, recall: 1.000, kappa: 0.000, time: 42.50s)\n",
      "Epoch (mode:  half body, lr: 0.004, loss: 0.65947, acc: 0.645, f1: 0.377, precision: 0.304, recall: 0.500, kappa: 0.000, time: 43.23s)\n",
      "Epoch (mode:      limbs, lr: 0.004, loss: 0.51716, acc: 0.792, f1: 0.881, precision: 0.792, recall: 1.000, kappa: 0.000, time: 45.53s)\n",
      "Epoch (mode:     joints, lr: 0.004, loss: 0.92365, acc: 0.837, f1: 0.622, precision: 0.801, recall: 0.865, kappa: 0.000, time: 52.95s)\n",
      "---  24 ---\n"
     ]
    }
   ],
   "source": [
    "model_columns = [\"epoch\", \"iteration\", \"joint_id\",\n",
    "                  \"gts\", \"preds\", \"confidences\", \n",
    "                  \"Avg loss\", \"loss\", \"accuracy\", \n",
    "                  \"tp\", \"tn\", \"fp\", \"fn\", \"precision\", \"recall\", \"f1\", \n",
    "                  \"cohens_kappa\", \"learning_rate\",\n",
    "                  \"train_test\", \"exercise\", \"simplified\", \"mode\", \"use_v2\"]\n",
    "                  \n",
    "df_model = pd.DataFrame(columns=model_columns)\n",
    "pb = tqdm(range(1, epochs + 1), desc='Epoch')\n",
    "\n",
    "for epoch in pb:\n",
    "    if all_modes:    \n",
    "        print(f\"--- {epoch:3d} ---\")\n",
    "        for mode, model, optimizer, scheduler, train_loader, _ in model_iterator:\n",
    "            tic = time()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            loss = train(train_loader, model, optimizer, CE, scheduler, clip, epoch, epochs, is_cuda, mode, df_model, use_v2)\n",
    "            crit_1 = df_model[\"epoch\"] == epoch\n",
    "            crit_2 = df_model[\"mode\"] == mode.name.lower()\n",
    "            last_row = df_model[crit_1 & crit_2].mean(numeric_only=True)\n",
    "            pb.set_description(f'Epoch (mode: {mode.name.lower().replace(\"_\", \" \"):>10}, lr: {optimizer.param_groups[0][\"lr\"]:.5f}, loss: {last_row[\"Avg loss\"]:.3f})')\n",
    "            \n",
    "            print(f'Epoch (mode: {mode.name.lower().replace(\"_\", \" \"):>10}, lr: {optimizer.param_groups[0][\"lr\"]:.3f}, loss: {last_row[\"Avg loss\"]:.5f}, acc: {last_row[\"accuracy\"]:.3f}, f1: {last_row[\"f1\"]:.3f}, precision: {last_row[\"precision\"]:.3f}, recall: {last_row[\"recall\"]:.3f}, kappa: {last_row[\"cohens_kappa\"]:.3f}, time: {time() - tic:.2f}s)')      \n",
    "\n",
    "            if (epoch) % 10 == 0:\n",
    "                torch.save(model.state_dict(), os.path.join(CHECKPOINT_DIR, f\"{mode.name.lower()}_{epoch}_ckpt.pth\")) \n",
    "    else:\n",
    "        tic = time()\n",
    "        torch.cuda.empty_cache()\n",
    "        loss = train(train_loader, model, optimizer, CE, scheduler, clip, epoch, epochs, is_cuda, mode, df_model, use_v2)\n",
    "\n",
    "        pb.set_description(f'Epoch (mode: {mode.name.lower().replace(\"_\", \" \"):>10}, lr: {optimizer.param_groups[0][\"lr\"]:.3e}, loss: {loss:.3e})')\n",
    "        \n",
    "        if (epoch) % 10 == 0:\n",
    "            torch.save(model.state_dict(), os.path.join(CHECKPOINT_DIR, f\"{epoch}_ckpt.pth\"))\n",
    "    \n",
    "if all_modes:\n",
    "    for mode, model, _, _, _, _ in model_iterator:\n",
    "        torch.save(model.state_dict(), os.path.join(CHECKPOINT_DIR, f\"{mode.name.lower()}_last_ckpt.pth\")) \n",
    "        print(f\"model saved {os.path.join(CHECKPOINT_DIR, f'last_ckpt.pth')}!\")\n",
    "else:\n",
    "    torch.save(model.state_dict(), os.path.join(CHECKPOINT_DIR, f\"last_ckpt.pth\"))\n",
    "    print(f\"model saved {os.path.join(CHECKPOINT_DIR, f'last_ckpt.pth')}!\")\n",
    "    checkpoint = os.path.join(CHECKPOINT_DIR, f\"last_ckpt.pth\")\n",
    "\n",
    "df_model.to_parquet('ModelAnalysis.parquet.gzip', compression='gzip') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5426da3453e2423da5029a02e5437c70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if all_modes:\n",
    "  for mode, model, _, _, _, test_loader in tqdm(model_iterator):\n",
    "    model.eval()\n",
    "    test(test_loader, model, CE, is_cuda, mode, df_model, use_v2)\n",
    "else: \n",
    "  model.eval()\n",
    "  test(test_loader, model, CE, is_cuda, mode, df_model, use_v2)\n",
    "  \n",
    "df_model.to_parquet('ModelAnalysis.parquet.gzip', compression='gzip') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.to_parquet('ModelAnalysis.parquet.gzip', compression='gzip') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "223e9e27cbc670f5c22c33ebc1577b54f1cca48f7f6b973b1c50992e7fee7cdc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
