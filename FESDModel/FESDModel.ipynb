{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FESDModel\n",
    "\n",
    "FESD - Fault estimation for skeleton detection - is a suite that aims at finding faults in joints of skeletons, which are detected by human pose estimatiors.\n",
    "\n",
    "FESDData is the sister project to this notebook, which aims at recording depth and rgb data, as well as populating the data with human poses from variing human pose estimators.\n",
    "\n",
    "Furthermore, FESTData augments all data based on joint confidence.\n",
    "\n",
    "FFESDModel aims to develop and evaluate a model based on the faulty and augmented joint data as well as RGBD data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "\n",
    "We need a range of libraries which are imported here. We also define some constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num cuda GPUs: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "\n",
    "from data import FESDDataset\n",
    "from data import Frame, AugmentationParams\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import cv2\n",
    "\n",
    "from model import FESD, FESDv2, train, val, test\n",
    "import copy\n",
    "\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import EfficientNet_V2_M_Weights\n",
    "\n",
    "import datetime\n",
    "\n",
    "from utils import AvgMeter, clip_gradient, get_scheduler\n",
    "from utils.mode import Mode\n",
    "from utils import err2gt, gt2err\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "num_gpus = torch.cuda.device_count()\n",
    "is_cuda = torch.cuda.is_available()\n",
    "print(f\"Num cuda GPUs: {num_gpus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECORDING_DIR = Path('D:/Recordings/')\n",
    "CHECKPOINT_DIR = Path('checkpoints')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Firstly we need to import all the recordings into the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(file=\"Exercises.json\", mode='r') as file:\n",
    "  exercises_json = json.load(file)['Exercises']\n",
    "\n",
    "with open(file=\"JointErrors.json\", mode='r') as file:\n",
    "  joint_error_json = json.load(file)\n",
    "\n",
    "with open(file=\"SkeletonErrors.json\", mode='r') as file:\n",
    "  skeleton_error_json = json.load(file)\n",
    "\n",
    "len(exercises_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recordings Found: 17\n",
      "Total Frames: 510\n",
      "Recordings Found: 9\n",
      "Total Frames: 270\n"
     ]
    }
   ],
   "source": [
    "batchsize = 40\n",
    "im_size = 32\n",
    "\n",
    "test_exercises = ['E-0.01', 'E-1.01', 'E-2.01', 'E-3.01']\n",
    "\n",
    "use_v2 = True\n",
    "if use_v2:\n",
    "  model = FESDv2\n",
    "else:\n",
    "  model = FESD\n",
    "\n",
    "dataset_train = FESDDataset(RECORDING_DIR, im_size, test_exercises, randomize_augmentation_params=True, use_v2=use_v2)\n",
    "dataset_train.randomize_augmentation_params = True\n",
    "\n",
    "dataset_test = FESDDataset(RECORDING_DIR, im_size, test_exercises, test=True, use_v2=use_v2)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batchsize)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_names_all = [\"-\", \"Head\", \"Neck\", \"Torso\", \"Waist\", \"Left collar\", \"Left shoulder\", \"Left elbow\", \"Left wrist\", \"Left hand\", \"-\", \"Right collar\", \"Right shoulder\", \"Right elbow\", \"Right wrist\", \"Right hand\", \"-\", \"Left hip\", \"Left knee\", \"Left ankle\", \"-\", \"Right hip\", \"Right knee\", \"Right ankle\", \"-\"]\n",
    "joint_names = [i for i in joint_names_all if i != '-']\n",
    "\n",
    "body_halves = np.array([\"Upper Half\", \"Lower Half\"])\n",
    "limbs = np.array([\"Head\", \"Torso\", \"Left arm\", \"Right arm\", \"Left leg\", \"Right leg\"])\n",
    "\n",
    "upper_body_i = [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "lower_body_i = [3, 14, 15, 16, 17, 18, 19]\n",
    "\n",
    "torso_i     = [2, 3, 4, 9]\n",
    "head_i      = [0, 1]\n",
    "left_arm_i  = [5, 6, 7, 8]\n",
    "right_arm_i = [10, 11, 12, 13]\n",
    "left_leg_i  = [14, 15, 16]\n",
    "right_leg_i = [17, 18, 19]\n",
    "\n",
    "joint_errors = []\n",
    "for je in joint_error_json:\n",
    "  joint_errors.append(je[\"Name\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Build the model according to the chosen mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to C:\\Users\\leona/.cache\\torch\\hub\\checkpoints\\efficientnet_v2_s-dd5fe13b.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c50dea0056864a4d80cb8365ac2b2e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/82.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_modes = True\n",
    "mode = Mode.FULL_BODY\n",
    "\n",
    "if all_modes:\n",
    "  model_full_body = nn.DataParallel(model(Mode.FULL_BODY.get_num_layers()))\n",
    "  model_half_body = nn.DataParallel(model(Mode.HALF_BODY.get_num_layers()))\n",
    "  model_limbs     = nn.DataParallel(model(Mode.LIMBS.get_num_layers()))\n",
    "  model_joints    = nn.DataParallel(model(Mode.JOINTS.get_num_layers()))\n",
    "else:\n",
    "  model = nn.DataParallel(model(mode.get_num_layers()))\n",
    "\n",
    "if is_cuda:\n",
    "  if all_modes:\n",
    "    model_full_body = model_full_body.cuda()\n",
    "    model_half_body = model_half_body.cuda()\n",
    "    model_limbs     = model_limbs.cuda()\n",
    "    model_joints    = model_joints.cuda()\n",
    "  else:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model\n",
    "\n",
    "In the following we define the training function and train a network on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recordings Found: 17\n",
      "Total Frames: 510\n",
      "Recordings Found: 9\n",
      "Total Frames: 270\n",
      "Recordings Found: 17\n",
      "Total Frames: 510\n",
      "Recordings Found: 9\n",
      "Total Frames: 270\n",
      "Recordings Found: 17\n",
      "Total Frames: 510\n",
      "Recordings Found: 9\n",
      "Total Frames: 270\n",
      "Recordings Found: 17\n",
      "Total Frames: 510\n",
      "Recordings Found: 9\n",
      "Total Frames: 270\n"
     ]
    }
   ],
   "source": [
    "if (all_modes):\n",
    "  train_loader_full_body  = torch.utils.data.DataLoader(FESDDataset(RECORDING_DIR, im_size, test_exercises=test_exercises, mode=Mode.FULL_BODY, randomize_augmentation_params=True, use_v2=use_v2), batch_size=batchsize, shuffle=True)\n",
    "  test_loader_full_body   = torch.utils.data.DataLoader(FESDDataset(RECORDING_DIR, im_size, test_exercises=test_exercises, mode=Mode.FULL_BODY, test=True, use_v2=use_v2))\n",
    "  train_loader_half_body  = torch.utils.data.DataLoader(FESDDataset(RECORDING_DIR, im_size, test_exercises=test_exercises, mode=Mode.HALF_BODY, randomize_augmentation_params=True, use_v2=use_v2), batch_size=batchsize, shuffle=True)\n",
    "  test_loader_half_body   = torch.utils.data.DataLoader(FESDDataset(RECORDING_DIR, im_size, test_exercises=test_exercises, mode=Mode.HALF_BODY, test=True, use_v2=use_v2))\n",
    "  train_loader_limbs      = torch.utils.data.DataLoader(FESDDataset(RECORDING_DIR, im_size, test_exercises=test_exercises, mode=Mode.LIMBS, randomize_augmentation_params=True, use_v2=use_v2), batch_size=batchsize, shuffle=True)\n",
    "  test_loader_limbs       = torch.utils.data.DataLoader(FESDDataset(RECORDING_DIR, im_size, test_exercises=test_exercises, mode=Mode.LIMBS, test=True, use_v2=use_v2))\n",
    "  train_loader_joints     = torch.utils.data.DataLoader(FESDDataset(RECORDING_DIR, im_size, test_exercises=test_exercises, mode=Mode.JOINTS, randomize_augmentation_params=True, use_v2=use_v2), batch_size=batchsize, shuffle=True)\n",
    "  test_loader_joints      = torch.utils.data.DataLoader(FESDDataset(RECORDING_DIR, im_size, test_exercises=test_exercises, mode=Mode.JOINTS, test=True, use_v2=use_v2))\n",
    "\n",
    "else:\n",
    "  train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batchsize)\n",
    "  test_loader = torch.utils.data.DataLoader(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader_half_body:\n",
    "  merged, _, _ = i\n",
    "  print(merged.size())\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "torchrun --nproc_per_node=8 train.py \\\n",
    "--model $MODEL --batch-size 128 --lr 0.5 --lr-scheduler cosineannealinglr \\\n",
    "--lr-warmup-epochs 5 --lr-warmup-method linear --auto-augment ta_wide --epochs 600 --random-erase 0.1 \\\n",
    "--label-smoothing 0.1 --mixup-alpha 0.2 --cutmix-alpha 1.0 --weight-decay 0.00002 --norm-weight-decay 0.0 \\\n",
    "--train-crop-size $TRAIN_SIZE --model-ema --val-crop-size $EVAL_SIZE --val-resize-size $EVAL_SIZE \\\n",
    "--ra-sampler --ra-reps 4\n",
    "\"\"\"\n",
    "\n",
    "# epoch number\n",
    "epochs = 100\n",
    "# optimizer\n",
    "optim = 'adam'\n",
    "# learning rate\n",
    "learning_rate = 0.005\n",
    "# learning rate scheduler. can be step, poly or cosine\n",
    "lr_scheduler = 'cosine'\n",
    "# warmup epoch\n",
    "warmup_epoch = 0\n",
    "# warmup multiplier\n",
    "warmup_multiplier = 100\n",
    "# for step scheduler. where to decay lr, can be a list\n",
    "lr_decay_epochs = [120, 160, 200]\n",
    "# for step scheduler. step size to decay lr\n",
    "lr_decay_steps = 20 \n",
    "# for step scheduler. decay rate for learning rate\n",
    "lr_decay_rate = 0.01\n",
    "# weight decay\n",
    "weight_decay = 0.0001\n",
    "# momentum for SGD\n",
    "momentum = 0.9\n",
    "# gradient clipping margin\n",
    "clip = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = len(train_loader.dataset)\n",
    "CE = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "if is_cuda:\n",
    "    CE = CE.cuda()\n",
    "\n",
    "if all_modes:\n",
    "    if optim == 'adam':\n",
    "        optimizer_full_body = torch.optim.Adam(model_full_body.parameters(),    learning_rate, weight_decay=weight_decay)\n",
    "        optimizer_half_body = torch.optim.Adam(model_half_body.parameters(),    learning_rate, weight_decay=weight_decay)\n",
    "        optimizer_limbs     = torch.optim.Adam(model_limbs.parameters(),        learning_rate, weight_decay=weight_decay)\n",
    "        optimizer_joints    = torch.optim.Adam(model_joints.parameters(),       learning_rate, weight_decay=weight_decay)\n",
    "    elif optim == 'adamW':\n",
    "        optimizer_full_body = torch.optim.AdamW(model_full_body.parameters(),   learning_rate, weight_decay=weight_decay)\n",
    "        optimizer_half_body = torch.optim.AdamW(model_half_body.parameters(),   learning_rate, weight_decay=weight_decay)\n",
    "        optimizer_limbs     = torch.optim.AdamW(model_limbs.parameters(),       learning_rate, weight_decay=weight_decay)\n",
    "        optimizer_joints    = torch.optim.AdamW(model_joints.parameters(),      learning_rate, weight_decay=weight_decay)\n",
    "    elif optim == 'sdg':\n",
    "        optimizer_full_body = torch.optim.SGD(model_full_body.parameters(),     learning_rate / 10.0 * batchsize, momentum=momentum, weight_decay=weight_decay)\n",
    "        optimizer_half_body = torch.optim.SGD(model_half_body.parameters(),     learning_rate / 10.0 * batchsize, momentum=momentum, weight_decay=weight_decay)\n",
    "        optimizer_limbs     = torch.optim.SGD(model_limbs.parameters(),         learning_rate / 10.0 * batchsize, momentum=momentum, weight_decay=weight_decay)\n",
    "        optimizer_joints    = torch.optim.SGD(model_joints.parameters(),        learning_rate / 10.0 * batchsize, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "    scheduler_full_body     = get_scheduler(optimizer_full_body, len(train_loader_full_body), lr_scheduler, lr_decay_epochs, lr_decay_steps, lr_decay_rate, epochs, warmup_epoch,     warmup_multiplier)\n",
    "    scheduler_half_body     = get_scheduler(optimizer_half_body, len(train_loader_half_body), lr_scheduler, lr_decay_epochs, lr_decay_steps, lr_decay_rate, epochs, warmup_epoch, warmup_multiplier)\n",
    "    scheduler_limbs         = get_scheduler(optimizer_limbs, len(train_loader_limbs), lr_scheduler, lr_decay_epochs, lr_decay_steps, lr_decay_rate, epochs, warmup_epoch, warmup_multiplier)\n",
    "    scheduler_joints        = get_scheduler(optimizer_joints, len(train_loader_joints), lr_scheduler, lr_decay_epochs, lr_decay_steps, lr_decay_rate, epochs, warmup_epoch, warmup_multiplier)\n",
    "else:\n",
    "    if optim == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), learning_rate, weight_decay=weight_decay)\n",
    "    elif optim == 'adamW':\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), learning_rate, weight_decay=weight_decay)\n",
    "    elif optim == 'sdg':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), learning_rate / 10.0 * batchsize, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "    scheduler = get_scheduler(optimizer, len(train_loader), lr_scheduler, lr_decay_epochs, lr_decay_steps, lr_decay_rate, epochs, warmup_epoch, warmup_multiplier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_modes:\n",
    "    model_iterator = list(zip([Mode.FULL_BODY,          Mode.HALF_BODY,         Mode.LIMBS,         Mode.JOINTS], \n",
    "                              [model_full_body,         model_half_body,        model_limbs,        model_joints], \n",
    "                              [optimizer_full_body,     optimizer_half_body,    optimizer_limbs,    optimizer_joints], \n",
    "                              [scheduler_full_body,     scheduler_half_body,    scheduler_limbs,    scheduler_joints],\n",
    "                              [train_loader_full_body,  train_loader_half_body, train_loader_limbs, train_loader_joints], \n",
    "                              [test_loader_full_body,   test_loader_half_body,  test_loader_limbs,  test_loader_joints]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8d8c059d0f4f10be284a74471bf455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---   1 ---\n",
      "Epoch (mode:  full body, lr: 0.005, loss: 0.768, acc: 0.560, f1: 0.715, precision: 0.565, recall: 0.984, kappa: -0.018, time: 171.15s)\n",
      "Epoch (mode:  half body, lr: 0.005, loss: 0.685, acc: 0.628, f1: 0.361, precision: 0.298, recall: 0.461, kappa: -0.030, time: 190.75s)\n",
      "Epoch (mode:      limbs, lr: 0.005, loss: 0.516, acc: 0.790, f1: 0.880, precision: 0.790, recall: 1.000, kappa: 0.000, time: 212.95s)\n",
      "Epoch (mode:     joints, lr: 0.005, loss: 0.901, acc: 0.835, f1: 0.622, precision: 0.800, recall: 0.865, kappa: 0.000, time: 247.20s)\n",
      "---   2 ---\n",
      "Epoch (mode:  full body, lr: 0.005, loss: 0.739, acc: 0.568, f1: 0.720, precision: 0.568, recall: 1.000, kappa: 0.000, time: 183.07s)\n",
      "Epoch (mode:  half body, lr: 0.005, loss: 0.662, acc: 0.640, f1: 0.371, precision: 0.303, recall: 0.482, kappa: -0.011, time: 195.93s)\n",
      "Epoch (mode:      limbs, lr: 0.005, loss: 0.545, acc: 0.793, f1: 0.881, precision: 0.793, recall: 1.000, kappa: 0.000, time: 244.04s)\n",
      "Epoch (mode:     joints, lr: 0.005, loss: 0.908, acc: 0.836, f1: 0.622, precision: 0.801, recall: 0.865, kappa: 0.000, time: 212.54s)\n",
      "---   3 ---\n",
      "Epoch (mode:  full body, lr: 0.005, loss: 0.744, acc: 0.572, f1: 0.722, precision: 0.572, recall: 1.000, kappa: 0.000, time: 224.48s)\n",
      "Epoch (mode:  half body, lr: 0.005, loss: 0.666, acc: 0.646, f1: 0.377, precision: 0.304, recall: 0.500, kappa: 0.000, time: 234.95s)\n",
      "Epoch (mode:      limbs, lr: 0.005, loss: 0.518, acc: 0.790, f1: 0.879, precision: 0.790, recall: 1.000, kappa: 0.000, time: 213.21s)\n",
      "Epoch (mode:     joints, lr: 0.005, loss: 0.908, acc: 0.836, f1: 0.622, precision: 0.801, recall: 0.865, kappa: 0.000, time: 182.91s)\n",
      "---   4 ---\n",
      "Epoch (mode:  full body, lr: 0.005, loss: 0.741, acc: 0.572, f1: 0.725, precision: 0.572, recall: 1.000, kappa: 0.000, time: 212.79s)\n",
      "Epoch (mode:  half body, lr: 0.005, loss: 0.647, acc: 0.647, f1: 0.378, precision: 0.306, recall: 0.500, kappa: 0.000, time: 203.59s)\n",
      "Epoch (mode:      limbs, lr: 0.005, loss: 0.525, acc: 0.790, f1: 0.880, precision: 0.790, recall: 1.000, kappa: 0.000, time: 217.12s)\n",
      "Epoch (mode:     joints, lr: 0.005, loss: 0.899, acc: 0.836, f1: 0.622, precision: 0.801, recall: 0.865, kappa: 0.000, time: 4796.39s)\n",
      "---   5 ---\n",
      "Epoch (mode:  full body, lr: 0.005, loss: 0.726, acc: 0.571, f1: 0.724, precision: 0.571, recall: 1.000, kappa: 0.000, time: 150.08s)\n",
      "Epoch (mode:  half body, lr: 0.005, loss: 0.678, acc: 0.645, f1: 0.377, precision: 0.304, recall: 0.500, kappa: 0.000, time: 157.11s)\n",
      "Epoch (mode:      limbs, lr: 0.005, loss: 0.496, acc: 0.788, f1: 0.877, precision: 0.788, recall: 1.000, kappa: 0.000, time: 152.00s)\n",
      "Epoch (mode:     joints, lr: 0.005, loss: 0.916, acc: 0.836, f1: 0.622, precision: 0.801, recall: 0.865, kappa: 0.000, time: 148.20s)\n",
      "---   6 ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m tic \u001b[39m=\u001b[39m time()\n\u001b[0;32m     16\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n\u001b[1;32m---> 18\u001b[0m loss \u001b[39m=\u001b[39m train(train_loader, model, optimizer, CE, scheduler, clip, epoch, epochs, is_cuda, mode, df_model, use_v2)\n\u001b[0;32m     19\u001b[0m crit_1 \u001b[39m=\u001b[39m df_model[\u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m epoch\n\u001b[0;32m     20\u001b[0m crit_2 \u001b[39m=\u001b[39m df_model[\u001b[39m\"\u001b[39m\u001b[39mmode\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m mode\u001b[39m.\u001b[39mname\u001b[39m.\u001b[39mlower()\n",
      "File \u001b[1;32md:\\FESD\\FESDModel\\model\\train.py:27\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, model, optimizer, criterion, scheduler, clip, epoch, epochs, is_cuda, mode, df, use_v2)\u001b[0m\n\u001b[0;32m     24\u001b[0m     gt \u001b[39m=\u001b[39m gt\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m     25\u001b[0m     merged_image \u001b[39m=\u001b[39m merged_image\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m---> 27\u001b[0m   pred \u001b[39m=\u001b[39m model(merged_image)\n\u001b[0;32m     28\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     29\u001b[0m   rgbs, depths, poses_2d, gt, session \u001b[39m=\u001b[39m pack\n",
      "File \u001b[1;32md:\\FESD\\FESDModel\\.env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\FESD\\FESDModel\\.env\\lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py:153\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(\u001b[39m\"\u001b[39m\u001b[39mDataParallel.forward\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    152\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids:\n\u001b[1;32m--> 153\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule(\u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    155\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m chain(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule\u001b[39m.\u001b[39mparameters(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule\u001b[39m.\u001b[39mbuffers()):\n\u001b[0;32m    156\u001b[0m         \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mdevice \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msrc_device_obj:\n",
      "File \u001b[1;32md:\\FESD\\FESDModel\\.env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\FESD\\FESDModel\\model\\model.py:111\u001b[0m, in \u001b[0;36mFESDv2.forward\u001b[1;34m(self, merged_image)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, merged_image):\n\u001b[0;32m    109\u001b[0m     \u001b[39m# Not sure if this works already or not\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mefficient_net\u001b[39m.\u001b[39;49mfeatures(merged_image)\n\u001b[0;32m    112\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool(x)\n\u001b[0;32m    113\u001b[0m     w \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32md:\\FESD\\FESDModel\\.env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\FESD\\FESDModel\\.env\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32md:\\FESD\\FESDModel\\.env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\FESD\\FESDModel\\.env\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32md:\\FESD\\FESDModel\\.env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\FESD\\FESDModel\\.env\\lib\\site-packages\\torchvision\\models\\efficientnet.py:165\u001b[0m, in \u001b[0;36mMBConv.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 165\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblock(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_res_connect:\n\u001b[0;32m    167\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstochastic_depth(result)\n",
      "File \u001b[1;32md:\\FESD\\FESDModel\\.env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\FESD\\FESDModel\\.env\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32md:\\FESD\\FESDModel\\.env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\FESD\\FESDModel\\.env\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32md:\\FESD\\FESDModel\\.env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\FESD\\FESDModel\\.env\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    164\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    166\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[0;32m    172\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[0;32m    173\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[0;32m    175\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[0;32m    176\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    177\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    178\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[0;32m    180\u001b[0m     bn_training,\n\u001b[0;32m    181\u001b[0m     exponential_average_factor,\n\u001b[0;32m    182\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[0;32m    183\u001b[0m )\n",
      "File \u001b[1;32md:\\FESD\\FESDModel\\.env\\lib\\site-packages\\torch\\nn\\functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2447\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[0;32m   2448\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[1;32m-> 2450\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[0;32m   2451\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[0;32m   2452\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_columns = [\"epoch\", \"iteration\", \"joint_id\",\n",
    "                  \"gts\", \"preds\", \"confidences\", \n",
    "                  \"Avg loss\", \"loss\", \"accuracy\", \n",
    "                  \"tp\", \"tn\", \"fp\", \"fn\", \"precision\", \"recall\", \"f1\", \n",
    "                  \"cohens_kappa\", \"learning_rate\",\n",
    "                  \"train_test\", \"exercise\", \"simplified\", \"mode\", \"use_v2\"]\n",
    "                  \n",
    "df_model = pd.DataFrame(columns=model_columns)\n",
    "pb = tqdm(range(1, epochs + 1), desc='Epoch')\n",
    "\n",
    "for epoch in pb:\n",
    "    if all_modes:    \n",
    "        print(f\"--- {epoch:3d} ---\")\n",
    "        for mode, model, optimizer, scheduler, train_loader, _ in model_iterator:\n",
    "            tic = time()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            loss = train(train_loader, model, optimizer, CE, scheduler, clip, epoch, epochs, is_cuda, mode, df_model, use_v2)\n",
    "            crit_1 = df_model[\"epoch\"] == epoch\n",
    "            crit_2 = df_model[\"mode\"] == mode.name.lower()\n",
    "            last_row = df_model[crit_1 & crit_2].mean(numeric_only=True)\n",
    "            pb.set_description(f'Epoch (mode: {mode.name.lower().replace(\"_\", \" \"):>10}, lr: {optimizer.param_groups[0][\"lr\"]:.5f}, loss: {last_row[\"Avg loss\"]:.3f})')\n",
    "            \n",
    "            print(f'Epoch (mode: {mode.name.lower().replace(\"_\", \" \"):>10}, lr: {optimizer.param_groups[0][\"lr\"]:.3f}, loss: {last_row[\"Avg loss\"]:.5f}, acc: {last_row[\"accuracy\"]:.3f}, f1: {last_row[\"f1\"]:.3f}, precision: {last_row[\"precision\"]:.3f}, recall: {last_row[\"recall\"]:.3f}, kappa: {last_row[\"cohens_kappa\"]:.3f}, time: {time() - tic:.2f}s)')      \n",
    "\n",
    "            if (epoch) % 10 == 0:\n",
    "                torch.save(model.state_dict(), os.path.join(CHECKPOINT_DIR, f\"{mode.name.lower()}_{epoch}_ckpt.pth\")) \n",
    "    else:\n",
    "        tic = time()\n",
    "        torch.cuda.empty_cache()\n",
    "        loss = train(train_loader, model, optimizer, CE, scheduler, clip, epoch, epochs, is_cuda, mode, df_model, use_v2)\n",
    "\n",
    "        pb.set_description(f'Epoch (mode: {mode.name.lower().replace(\"_\", \" \"):>10}, lr: {optimizer.param_groups[0][\"lr\"]:.3e}, loss: {loss:.3e})')\n",
    "        \n",
    "        if (epoch) % 10 == 0:\n",
    "            torch.save(model.state_dict(), os.path.join(CHECKPOINT_DIR, f\"{epoch}_ckpt.pth\"))\n",
    "    \n",
    "if all_modes:\n",
    "    for mode, model, _, _, _, _ in model_iterator:\n",
    "        torch.save(model.state_dict(), os.path.join(CHECKPOINT_DIR, f\"{mode.name.lower()}_last_ckpt.pth\")) \n",
    "        print(f\"model saved {os.path.join(CHECKPOINT_DIR, f'last_ckpt.pth')}!\")\n",
    "else:\n",
    "    torch.save(model.state_dict(), os.path.join(CHECKPOINT_DIR, f\"last_ckpt.pth\"))\n",
    "    print(f\"model saved {os.path.join(CHECKPOINT_DIR, f'last_ckpt.pth')}!\")\n",
    "    checkpoint = os.path.join(CHECKPOINT_DIR, f\"last_ckpt.pth\")\n",
    "\n",
    "df_model.to_parquet('ModelAnalysis.parquet.gzip', compression='gzip') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>iteration</th>\n",
       "      <th>joint_id</th>\n",
       "      <th>gts</th>\n",
       "      <th>preds</th>\n",
       "      <th>confidences</th>\n",
       "      <th>Avg loss</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>tp</th>\n",
       "      <th>...</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>cohens_kappa</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>train_test</th>\n",
       "      <th>exercise</th>\n",
       "      <th>simplified</th>\n",
       "      <th>mode</th>\n",
       "      <th>use_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0, 0.0]</td>\n",
       "      <td>[0.5121623277664185, 0.5606511831283569, 0.508...</td>\n",
       "      <td>0.140238</td>\n",
       "      <td>0.140238</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>train</td>\n",
       "      <td>E-2.03</td>\n",
       "      <td>True</td>\n",
       "      <td>full_body</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0]</td>\n",
       "      <td>[0.7705711722373962, 0.8028934001922607, 0.759...</td>\n",
       "      <td>0.708748</td>\n",
       "      <td>1.277259</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>train</td>\n",
       "      <td>E-0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>full_body</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.5, 0.5, 0.5]</td>\n",
       "      <td>0.472499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>train</td>\n",
       "      <td>E-1.02</td>\n",
       "      <td>True</td>\n",
       "      <td>full_body</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.5, 0.5, 0.5]</td>\n",
       "      <td>0.354374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>train</td>\n",
       "      <td>E-3.00</td>\n",
       "      <td>True</td>\n",
       "      <td>full_body</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.5, 0.5, 0.5]</td>\n",
       "      <td>0.283499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>train</td>\n",
       "      <td>E-1.03</td>\n",
       "      <td>True</td>\n",
       "      <td>full_body</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33453</th>\n",
       "      <td>5</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.5, 0.5, 0.5]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>train</td>\n",
       "      <td>E-2.03</td>\n",
       "      <td>True</td>\n",
       "      <td>full_body</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33454</th>\n",
       "      <td>5</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.5, 0.5, 0.5]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>train</td>\n",
       "      <td>E-2.02</td>\n",
       "      <td>True</td>\n",
       "      <td>full_body</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33455</th>\n",
       "      <td>5</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.5, 0.5, 0.5]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>train</td>\n",
       "      <td>E-2.03</td>\n",
       "      <td>True</td>\n",
       "      <td>full_body</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33456</th>\n",
       "      <td>5</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.5, 0.5, 0.5]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>train</td>\n",
       "      <td>E-2.00</td>\n",
       "      <td>True</td>\n",
       "      <td>full_body</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33457</th>\n",
       "      <td>5</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.5, 0.5, 0.5]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004971</td>\n",
       "      <td>train</td>\n",
       "      <td>E-1.02</td>\n",
       "      <td>True</td>\n",
       "      <td>full_body</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33458 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       epoch  iteration  joint_id              gts            preds  \\\n",
       "0          1          1         0  [0.0, 0.0, 0.0]  [1.0, 1.0, 0.0]   \n",
       "1          1          2         0  [0.0, 0.0, 1.0]  [1.0, 1.0, 1.0]   \n",
       "2          1          3         0  [0.0, 1.0, 0.0]  [0.0, 0.0, 0.0]   \n",
       "3          1          4         0  [1.0, 1.0, 0.0]  [0.0, 0.0, 0.0]   \n",
       "4          1          5         0  [0.0, 1.0, 0.0]  [0.0, 0.0, 0.0]   \n",
       "...      ...        ...       ...              ...              ...   \n",
       "33453      5        134         0  [0.0, 0.0, 0.0]  [0.0, 0.0, 0.0]   \n",
       "33454      5        135         0  [0.0, 0.0, 1.0]  [0.0, 0.0, 0.0]   \n",
       "33455      5        136         0  [0.0, 1.0, 0.0]  [0.0, 0.0, 0.0]   \n",
       "33456      5        137         0  [1.0, 1.0, 0.0]  [0.0, 0.0, 0.0]   \n",
       "33457      5        138         0  [0.0, 0.0, 1.0]  [0.0, 0.0, 0.0]   \n",
       "\n",
       "                                             confidences  Avg loss      loss  \\\n",
       "0      [0.5121623277664185, 0.5606511831283569, 0.508...  0.140238  0.140238   \n",
       "1      [0.7705711722373962, 0.8028934001922607, 0.759...  0.708748  1.277259   \n",
       "2                                        [0.5, 0.5, 0.5]  0.472499  0.000000   \n",
       "3                                        [0.5, 0.5, 0.5]  0.354374  0.000000   \n",
       "4                                        [0.5, 0.5, 0.5]  0.283499  0.000000   \n",
       "...                                                  ...       ...       ...   \n",
       "33453                                    [0.5, 0.5, 0.5]  0.000000  0.000000   \n",
       "33454                                    [0.5, 0.5, 0.5]  0.000000  0.000000   \n",
       "33455                                    [0.5, 0.5, 0.5]  0.000000  0.000000   \n",
       "33456                                    [0.5, 0.5, 0.5]  0.000000  0.000000   \n",
       "33457                                    [0.5, 0.5, 0.5]  0.000000  0.000000   \n",
       "\n",
       "       accuracy   tp  ...  precision    recall   f1  cohens_kappa  \\\n",
       "0      0.333333  1.0  ...   1.000000  0.333333  0.5           0.0   \n",
       "1      0.333333  0.0  ...   0.000000  0.000000  0.0           0.0   \n",
       "2      0.666667  2.0  ...   0.666667  1.000000  0.8           0.0   \n",
       "3      0.333333  1.0  ...   0.333333  1.000000  0.5           0.0   \n",
       "4      0.666667  2.0  ...   0.666667  1.000000  0.8           0.0   \n",
       "...         ...  ...  ...        ...       ...  ...           ...   \n",
       "33453  1.000000  3.0  ...   1.000000  1.000000  1.0           NaN   \n",
       "33454  0.666667  2.0  ...   0.666667  1.000000  0.8           0.0   \n",
       "33455  0.666667  2.0  ...   0.666667  1.000000  0.8           0.0   \n",
       "33456  0.333333  1.0  ...   0.333333  1.000000  0.5           0.0   \n",
       "33457  0.666667  2.0  ...   0.666667  1.000000  0.8           0.0   \n",
       "\n",
       "       learning_rate  train_test  exercise  simplified       mode use_v2  \n",
       "0           0.005000       train    E-2.03        True  full_body   True  \n",
       "1           0.005000       train    E-0.00        True  full_body   True  \n",
       "2           0.005000       train    E-1.02        True  full_body   True  \n",
       "3           0.005000       train    E-3.00        True  full_body   True  \n",
       "4           0.005000       train    E-1.03        True  full_body   True  \n",
       "...              ...         ...       ...         ...        ...    ...  \n",
       "33453       0.004972       train    E-2.03        True  full_body   True  \n",
       "33454       0.004972       train    E-2.02        True  full_body   True  \n",
       "33455       0.004972       train    E-2.03        True  full_body   True  \n",
       "33456       0.004972       train    E-2.00        True  full_body   True  \n",
       "33457       0.004971       train    E-1.02        True  full_body   True  \n",
       "\n",
       "[33458 rows x 23 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5426da3453e2423da5029a02e5437c70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if all_modes:\n",
    "  for mode, model, _, _, _, test_loader in tqdm(model_iterator):\n",
    "    model.eval()\n",
    "    test(test_loader, model, CE, is_cuda, mode, df_model, use_v2)\n",
    "else: \n",
    "  model.eval()\n",
    "  test(test_loader, model, CE, is_cuda, mode, df_model, use_v2)\n",
    "  \n",
    "df_model.to_parquet('ModelAnalysis.parquet.gzip', compression='gzip') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.to_parquet('ModelAnalysis.parquet.gzip', compression='gzip') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "223e9e27cbc670f5c22c33ebc1577b54f1cca48f7f6b973b1c50992e7fee7cdc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
