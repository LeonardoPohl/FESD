{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FESDModel\n",
    "\n",
    "FESD - Fault estimation for skeleton detection - is a suite that aims at finding faults in joints of skeletons, which are detected by human pose estimatiors.\n",
    "\n",
    "FESDData is the sister project to this notebook, which aims at recording depth and rgb data, as well as populating the data with human poses from variing human pose estimators.\n",
    "\n",
    "Furthermore, FESTData augments all data based on joint confidence.\n",
    "\n",
    "FFESDModel aims to develop and evaluate a model based on the faulty and augmented joint data as well as RGBD data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "\n",
    "We need a range of libraries which are imported here. We also define some constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num cuda GPUs: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from model import FESD, FESDv2, train, val, test\n",
    "\n",
    "from utils.mode import Mode\n",
    "from utils import get_model_iter, get_model_iter_all\n",
    "\n",
    "from data import Frame\n",
    "\n",
    "\n",
    "num_gpus = torch.cuda.device_count()\n",
    "is_cuda = torch.cuda.is_available()\n",
    "print(f\"Num cuda GPUs: {num_gpus}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Build the model according to the chosen mode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model\n",
    "\n",
    "In the following we define the training function and train a network on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(780 / 26) * len(['E-0.00', 'E-0.01', 'E-1.00', 'E-1.02', 'E-2.00', 'E-2.03', 'E-3.00', 'E-3.02'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7963db06b89545b09b5972abf44b177a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---   1 ---\n",
      "Epoch (mode: body parts, lr: 0.001, loss: 0.38594, acc: 0.873, f1: 0.873, precision: 0.873, recall: 0.873, kappa: 0.000, p/(p + n): 1.000, time: 403.26s)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 60\u001b[0m\n\u001b[0;32m     57\u001b[0m tic \u001b[39m=\u001b[39m time()\n\u001b[0;32m     58\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n\u001b[1;32m---> 60\u001b[0m train(train_loader, model, optimizer, CE, scheduler, clip, epoch, is_cuda, mode, df_model, use_v2)\n\u001b[0;32m     61\u001b[0m test(test_loader, model, CE, epoch, is_cuda, mode, df_model, use_v2)\n\u001b[0;32m     63\u001b[0m crit_1 \u001b[39m=\u001b[39m df_model[\u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m epoch\n",
      "File \u001b[1;32md:\\FESD\\FESDModel\\model\\train.py:16\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, model, optimizer, criterion, scheduler, clip, epoch, is_cuda, mode, df, use_v2)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(train_loader: DataLoader, model, optimizer, criterion, scheduler, clip, epoch, is_cuda, mode, df, use_v2):\n\u001b[0;32m     14\u001b[0m   loss_record \u001b[39m=\u001b[39m AvgMeter()\n\u001b[1;32m---> 16\u001b[0m   \u001b[39mfor\u001b[39;00m i, pack \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader, start\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m     17\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     19\u001b[0m     \u001b[39mif\u001b[39;00m use_v2:      \n",
      "File \u001b[1;32md:\\FESD\\FESDModel\\.env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\FESD\\FESDModel\\.env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\FESD\\FESDModel\\.env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\FESD\\FESDModel\\.env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\FESD\\FESDModel\\data\\dataset.py:85\u001b[0m, in \u001b[0;36mFESDDataset.__getitem__\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandomize_augmentation_params:\n\u001b[0;32m     83\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maugmentation_params\u001b[39m.\u001b[39mRandomize()\n\u001b[1;32m---> 85\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframe \u001b[39m=\u001b[39m load_frame(recording_dir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrecording_dir, session\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrecording_jsons[session], frame_id\u001b[39m=\u001b[39;49mindex, params\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maugmentation_params, mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode, use_v2\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muse_v2)\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_v2:\n\u001b[0;32m     88\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_frame_v2()\n",
      "File \u001b[1;32md:\\FESD\\FESDModel\\data\\frame_loader.py:152\u001b[0m, in \u001b[0;36mload_frame\u001b[1;34m(recording_dir, session, frame_id, params, mode, use_v2)\u001b[0m\n\u001b[0;32m    149\u001b[0m pose_im \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros_like(depth)\n\u001b[0;32m    151\u001b[0m \u001b[39mfor\u001b[39;00m pose \u001b[39min\u001b[39;00m pose_2d:\n\u001b[1;32m--> 152\u001b[0m   coords \u001b[39m=\u001b[39m [(\u001b[39mint\u001b[39m(\u001b[39mmin\u001b[39m(\u001b[39mmax\u001b[39m(\u001b[39m0\u001b[39m, pose[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m x), rgb\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)), \u001b[39mint\u001b[39m(\u001b[39mmin\u001b[39m(\u001b[39mmax\u001b[39m(\u001b[39m0\u001b[39m, pose[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m y), rgb\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m))) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m) \u001b[39mfor\u001b[39;00m y \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m)]\n\u001b[0;32m    154\u001b[0m   \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m coords:\n\u001b[0;32m    155\u001b[0m     pose_im[x, y] \u001b[39m=\u001b[39m \u001b[39m255\u001b[39m\n",
      "File \u001b[1;32md:\\FESD\\FESDModel\\data\\frame_loader.py:152\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    149\u001b[0m pose_im \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros_like(depth)\n\u001b[0;32m    151\u001b[0m \u001b[39mfor\u001b[39;00m pose \u001b[39min\u001b[39;00m pose_2d:\n\u001b[1;32m--> 152\u001b[0m   coords \u001b[39m=\u001b[39m [(\u001b[39mint\u001b[39m(\u001b[39mmin\u001b[39;49m(\u001b[39mmax\u001b[39;49m(\u001b[39m0\u001b[39;49m, pose[\u001b[39m1\u001b[39;49m] \u001b[39m+\u001b[39;49m x), rgb\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m] \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m)), \u001b[39mint\u001b[39m(\u001b[39mmin\u001b[39m(\u001b[39mmax\u001b[39m(\u001b[39m0\u001b[39m, pose[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m y), rgb\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m))) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m) \u001b[39mfor\u001b[39;00m y \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m)]\n\u001b[0;32m    154\u001b[0m   \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m coords:\n\u001b[0;32m    155\u001b[0m     pose_im[x, y] \u001b[39m=\u001b[39m \u001b[39m255\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batchsize = 32\n",
    "im_size = 300\n",
    "epochs = 50\n",
    "# gradient clipping margin\n",
    "clip = 0.5\n",
    "label_smoothing = 0.0\n",
    "learning_rate = 0.0001\n",
    "\n",
    "test_exercises = ['E-0.00', 'E-0.01', 'E-1.00', 'E-1.02', 'E-2.00', 'E-2.03', 'E-3.00', 'E-3.02']\n",
    "\n",
    "all_modes = True\n",
    "if not all_modes:\n",
    "    mode = Mode.FULL_BODY\n",
    "\n",
    "model_columns = [\"epoch\", \"iteration\", \"joint_id\",\n",
    "                  \"gts\", \"preds\", \"confidences\", \n",
    "                  \"Avg loss\", \"loss\", \"accuracy\", \n",
    "                  \"tp\", \"tn\", \"fp\", \"fn\", \"precision\", \"recall\", \"f1\", \n",
    "                  \"cohens_kappa\", \"learning_rate\",\n",
    "                  \"train_test\", \"exercise\", \"simplified\", \"mode\", \"use_v2\"]\n",
    "                  \n",
    "for use_v2 in [False, True]:\n",
    "  model_id = f\"{'v2' if use_v2 else 'v1'}{'' if all_modes else '_' + mode.to_str()}_bs_{batchsize}_is_{im_size}_e_{epochs}_ls_{label_smoothing}_lr_{learning_rate}\"\n",
    "\n",
    "  CE = torch.nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "  if is_cuda:\n",
    "      CE = CE.cuda()\n",
    "\n",
    "  model_iterator = []\n",
    "  if all_modes:\n",
    "      model_iterator = get_model_iter_all(is_cuda, use_v2, test_exercises, epochs, batchsize, im_size, clip, learning_rate)\n",
    "  else:\n",
    "      model_iterator = get_model_iter(mode, is_cuda, use_v2, test_exercises, epochs, batchsize, im_size, clip, learning_rate)\n",
    "                    \n",
    "  df_model = pd.DataFrame(columns=model_columns)\n",
    "  pb = tqdm(range(1, epochs + 1), desc='Epoch')\n",
    "\n",
    "  model_result_dir = f\"./results/{model_id}\"\n",
    "  dir_fallback = \"_are_you_kidding_me_with_this_many_models\"\n",
    "\n",
    "  try:\n",
    "    Path(model_result_dir).mkdir(parents=True)\n",
    "  except:\n",
    "    for i in dir_fallback:\n",
    "      model_result_dir += f\"{i}\"\n",
    "      try:\n",
    "        Path(model_result_dir).mkdir(parents=True)\n",
    "        break\n",
    "      except:\n",
    "        pass\n",
    "\n",
    "  model_result_dir = Path(model_result_dir)\n",
    "\n",
    "  for epoch in pb:\n",
    "      print(f\"--- {epoch:3d} ---\")\n",
    "      for mode, model, optimizer, scheduler, train_loader, test_loader in model_iterator:\n",
    "          tic = time()\n",
    "          torch.cuda.empty_cache()\n",
    "          \n",
    "          train(train_loader, model, optimizer, CE, scheduler, clip, epoch, is_cuda, mode, df_model, use_v2)\n",
    "          test(test_loader, model, CE, epoch, is_cuda, mode, df_model, use_v2)\n",
    "\n",
    "          crit_1 = df_model[\"epoch\"] == epoch\n",
    "          crit_2 = df_model[\"mode\"] == mode.name.lower()\n",
    "          crit_3 = df_model[\"train_test\"] == \"test\"\n",
    "          last_row = df_model[crit_1 & crit_2 & crit_3].mean(numeric_only=True)\n",
    "          last_row[\"p\"] = last_row[\"tp\"] + last_row[\"fp\"]\n",
    "          last_row[\"n\"] = last_row[\"tn\"] + last_row[\"fn\"]\n",
    "          tp = df_model[crit_1 & crit_2 & crit_3][\"tp\"].sum()\n",
    "          tn = df_model[crit_1 & crit_2 & crit_3][\"tn\"].sum()\n",
    "          fp = df_model[crit_1 & crit_2 & crit_3][\"fp\"].sum()\n",
    "          fn = df_model[crit_1 & crit_2 & crit_3][\"fn\"].sum()\n",
    "          kappa = (2 * (tp * tn) - (fn * fp)) / ((tp + fp) * (fp + tn) + (tp + fn) * (fn + tn))\n",
    "          df_model[crit_1 & crit_2 & crit_3][\"cohens_kappa\"] = kappa\n",
    "          last_row[\"positives\"] = last_row[\"p\"] / (last_row[\"n\"] + last_row[\"p\"])\n",
    "          pb.set_description(f'Epoch (mode: {mode.name.lower().replace(\"_\", \" \"):>10}, lr: {optimizer.param_groups[0][\"lr\"]:.5f}, loss: {last_row[\"Avg loss\"]:.3f})')\n",
    "          \n",
    "          print(f'Epoch (mode: {mode.name.lower().replace(\"_\", \" \"):>10}, lr: {optimizer.param_groups[0][\"lr\"]:.3f}, loss: {last_row[\"Avg loss\"]:.5f}, acc: {last_row[\"accuracy\"]:.3f}, f1: {last_row[\"f1\"]:.3f}, precision: {last_row[\"precision\"]:.3f}, recall: {last_row[\"recall\"]:.3f}, kappa: {kappa:.3f}, p/(p + n): {last_row[\"positives\"]:.3f}, time: {time() - tic:.2f}s)')        \n",
    "\n",
    "          if (epoch) % 10 == 0:\n",
    "              torch.save(model.state_dict(), os.path.join(Path('checkpoints'), f\"{model_id}_{mode.name.lower()}_{epoch}_ckpt.pth\")) \n",
    "      \n",
    "  for mode, model, _, _, _, _ in model_iterator:\n",
    "      torch.save(model.state_dict(), model_result_dir / f\"{mode.name.lower()}_last_ckpt.pth\") \n",
    "      print(f\"model saved {os.path.join(model_result_dir, f'last_ckpt.pth')}!\")\n",
    "\n",
    "  df_model.to_parquet(model_result_dir / f'ModelAnalysis.parquet.gzip', compression='gzip') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "223e9e27cbc670f5c22c33ebc1577b54f1cca48f7f6b973b1c50992e7fee7cdc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
