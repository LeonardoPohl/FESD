{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FESDModel\n",
    "\n",
    "FESD - Fault estimation for skeleton detection - is a suite that aims at finding faults in joints of skeletons, which are detected by human pose estimatiors.\n",
    "\n",
    "FESDData is the sister project to this notebook, which aims at recording depth and rgb data, as well as populating the data with human poses from variing human pose estimators.\n",
    "\n",
    "Furthermore, FESTData augments all data based on joint confidence.\n",
    "\n",
    "FFESDModel aims to develop and evaluate a model based on the faulty and augmented joint data as well as RGBD data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "\n",
    "We need a range of libraries which are imported here. We also define some constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from model import FESD, FESDv2, train, val, test\n",
    "\n",
    "from utils.mode import Mode\n",
    "from utils import get_model_iter, get_model_iter_all\n",
    "\n",
    "from data import Frame\n",
    "\n",
    "\n",
    "num_gpus = torch.cuda.device_count()\n",
    "is_cuda = torch.cuda.is_available()\n",
    "print(f\"Num cuda GPUs: {num_gpus}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Build the model according to the chosen mode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model\n",
    "\n",
    "In the following we define the training function and train a network on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(780 / 26) * len(['E-0.00', 'E-0.01', 'E-1.00', 'E-1.02', 'E-2.00', 'E-2.03', 'E-3.00', 'E-3.02'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 32\n",
    "im_size = 300\n",
    "epochs = 50\n",
    "# gradient clipping margin\n",
    "clip = 0.5\n",
    "label_smoothing = 0.0\n",
    "learning_rate = 0.0001\n",
    "\n",
    "test_exercises = ['E-0.00', 'E-0.01', 'E-1.00', 'E-1.02', 'E-2.00', 'E-2.03', 'E-3.00', 'E-3.02']\n",
    "\n",
    "all_modes = True\n",
    "if not all_modes:\n",
    "    mode = Mode.FULL_BODY\n",
    "\n",
    "model_columns = [\"epoch\", \"iteration\", \"joint_id\",\n",
    "                  \"gts\", \"preds\", \"confidences\", \n",
    "                  \"Avg loss\", \"loss\", \"accuracy\", \n",
    "                  \"tp\", \"tn\", \"fp\", \"fn\", \"precision\", \"recall\", \"f1\", \n",
    "                  \"cohens_kappa\", \"learning_rate\",\n",
    "                  \"train_test\", \"exercise\", \"simplified\", \"mode\", \"use_v2\"]\n",
    "                  \n",
    "for use_v2 in [False, True]:\n",
    "  model_id = f\"{'v2' if use_v2 else 'v1'}{'' if all_modes else '_' + mode.to_str()}_bs_{batchsize}_is_{im_size}_e_{epochs}_ls_{label_smoothing}_lr_{learning_rate}\"\n",
    "\n",
    "  CE = torch.nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "  if is_cuda:\n",
    "      CE = CE.cuda()\n",
    "\n",
    "  model_iterator = []\n",
    "  if all_modes:\n",
    "      model_iterator = get_model_iter_all(is_cuda, use_v2, test_exercises, epochs, batchsize, im_size, clip, learning_rate)\n",
    "  else:\n",
    "      model_iterator = get_model_iter(mode, is_cuda, use_v2, test_exercises, epochs, batchsize, im_size, clip, learning_rate)\n",
    "                    \n",
    "  df_model = pd.DataFrame(columns=model_columns)\n",
    "  pb = tqdm(range(1, epochs + 1), desc='Epoch')\n",
    "\n",
    "  model_result_dir = f\"./results/{model_id}\"\n",
    "  dir_fallback = \"_are_you_kidding_me_with_this_many_models\"\n",
    "\n",
    "  try:\n",
    "    Path(model_result_dir).mkdir(parents=True)\n",
    "  except:\n",
    "    for i in dir_fallback:\n",
    "      model_result_dir += f\"{i}\"\n",
    "      try:\n",
    "        Path(model_result_dir).mkdir(parents=True)\n",
    "        break\n",
    "      except:\n",
    "        pass\n",
    "\n",
    "  model_result_dir = Path(model_result_dir)\n",
    "\n",
    "  for epoch in pb:\n",
    "      print(f\"--- {epoch:3d} ---\")\n",
    "      for mode, model, optimizer, scheduler, train_loader, test_loader in model_iterator:\n",
    "          tic = time()\n",
    "          torch.cuda.empty_cache()\n",
    "          \n",
    "          train(train_loader, model, optimizer, CE, scheduler, clip, epoch, is_cuda, mode, df_model, use_v2)\n",
    "          test(test_loader, model, CE, epoch, is_cuda, mode, df_model, use_v2)\n",
    "\n",
    "          crit_1 = df_model[\"epoch\"] == epoch\n",
    "          crit_2 = df_model[\"mode\"] == mode.name.lower()\n",
    "          crit_3 = df_model[\"train_test\"] == \"test\"\n",
    "          last_row = df_model[crit_1 & crit_2 & crit_3].mean(numeric_only=True)\n",
    "          last_row[\"p\"] = last_row[\"tp\"] + last_row[\"fp\"]\n",
    "          last_row[\"n\"] = last_row[\"tn\"] + last_row[\"fn\"]\n",
    "          tp = df_model[crit_1 & crit_2 & crit_3][\"tp\"].sum()\n",
    "          tn = df_model[crit_1 & crit_2 & crit_3][\"tn\"].sum()\n",
    "          fp = df_model[crit_1 & crit_2 & crit_3][\"fp\"].sum()\n",
    "          fn = df_model[crit_1 & crit_2 & crit_3][\"fn\"].sum()\n",
    "          kappa = (2 * (tp * tn) - (fn * fp)) / ((tp + fp) * (fp + tn) + (tp + fn) * (fn + tn))\n",
    "          df_model[crit_1 & crit_2 & crit_3][\"cohens_kappa\"] = kappa\n",
    "          last_row[\"positives\"] = last_row[\"p\"] / (last_row[\"n\"] + last_row[\"p\"])\n",
    "          pb.set_description(f'Epoch (mode: {mode.name.lower().replace(\"_\", \" \"):>10}, lr: {optimizer.param_groups[0][\"lr\"]:.5f}, loss: {last_row[\"Avg loss\"]:.3f})')\n",
    "          \n",
    "          print(f'Epoch (mode: {mode.name.lower().replace(\"_\", \" \"):>10}, lr: {optimizer.param_groups[0][\"lr\"]:.3f}, loss: {last_row[\"Avg loss\"]:.5f}, acc: {last_row[\"accuracy\"]:.3f}, f1: {last_row[\"f1\"]:.3f}, precision: {last_row[\"precision\"]:.3f}, recall: {last_row[\"recall\"]:.3f}, kappa: {kappa:.3f}, p/(p + n): {last_row[\"positives\"]:.3f}, time: {time() - tic:.2f}s)')        \n",
    "\n",
    "          if (epoch) % 10 == 0:\n",
    "              torch.save(model.state_dict(), os.path.join(Path('checkpoints'), f\"{model_id}_{mode.name.lower()}_{epoch}_ckpt.pth\")) \n",
    "      \n",
    "  for mode, model, _, _, _, _ in model_iterator:\n",
    "      torch.save(model.state_dict(), model_result_dir / f\"{mode.name.lower()}_last_ckpt.pth\") \n",
    "      print(f\"model saved {os.path.join(model_result_dir, f'last_ckpt.pth')}!\")\n",
    "\n",
    "  df_model.to_parquet(model_result_dir / f'ModelAnalysis.parquet.gzip', compression='gzip') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "223e9e27cbc670f5c22c33ebc1577b54f1cca48f7f6b973b1c50992e7fee7cdc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
