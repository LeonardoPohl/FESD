{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num cuda GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "\n",
    "from data import FESDDataset\n",
    "from data import Frame, AugmentationParams\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import cv2\n",
    "\n",
    "from model import FESD, train, val, test\n",
    "import copy\n",
    "\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import datetime\n",
    "\n",
    "from utils import AvgMeter, clip_gradient, get_scheduler\n",
    "from utils.mode import Mode\n",
    "from utils import err2gt, gt2err\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "num_gpus = torch.cuda.device_count()\n",
    "is_cuda = torch.cuda.is_available()\n",
    "print(f\"Num cuda GPUs: {num_gpus}\")\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECORDING_DIR = Path('H:/Recordings/')\n",
    "CHECKPOINT_DIR = Path('checkpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Firstly we need to import all the recordings into the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(file=\"Exercises.json\", mode='r') as file:\n",
    "  exercises_json = json.load(file)['Exercises']\n",
    "\n",
    "with open(file=\"JointErrors.json\", mode='r') as file:\n",
    "  joint_error_json = json.load(file)\n",
    "\n",
    "with open(file=\"SkeletonErrors.json\", mode='r') as file:\n",
    "  skeleton_error_json = json.load(file)\n",
    "\n",
    "len(exercises_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recordings Found: 17\n",
      "Total Frames: 510\n",
      "Recordings Found: 9\n",
      "Total Frames: 270\n",
      "51\n",
      "270\n"
     ]
    }
   ],
   "source": [
    "batchsize = 10\n",
    "im_size = 300\n",
    "\n",
    "test_exercises = ['E-0.01', 'E-1.01', 'E-2.01', 'E-3.01']\n",
    "\n",
    "dataset_train = FESDDataset(RECORDING_DIR, im_size, test_exercises, randomize_augmentation_params=True)\n",
    "dataset_train.randomize_augmentation_params = True\n",
    "\n",
    "dataset_test = FESDDataset(RECORDING_DIR, im_size, test_exercises, test=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batchsize)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_names_all = [\"-\", \"Head\", \"Neck\", \"Torso\", \"Waist\", \"Left collar\", \"Left shoulder\", \"Left elbow\", \"Left wrist\", \"Left hand\", \"-\", \"Right collar\", \"Right shoulder\", \"Right elbow\", \"Right wrist\", \"Right hand\", \"-\", \"Left hip\", \"Left knee\", \"Left ankle\", \"-\", \"Right hip\", \"Right knee\", \"Right ankle\", \"-\"]\n",
    "joint_names = [i for i in joint_names_all if i != '-']\n",
    "\n",
    "body_halves = np.array([\"Upper Half\", \"Lower Half\"])\n",
    "limbs = np.array([\"Head\", \"Torso\", \"Left arm\", \"Right arm\", \"Left leg\", \"Right leg\"])\n",
    "\n",
    "upper_body_i = [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "lower_body_i = [3, 14, 15, 16, 17, 18, 19]\n",
    "\n",
    "torso_i     = [2, 3, 4, 9]\n",
    "head_i      = [0, 1]\n",
    "left_arm_i  = [5, 6, 7, 8]\n",
    "right_arm_i = [10, 11, 12, 13]\n",
    "left_leg_i  = [14, 15, 16]\n",
    "right_leg_i = [17, 18, 19]\n",
    "\n",
    "joint_errors = []\n",
    "for je in joint_error_json:\n",
    "  joint_errors.append(je[\"Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 500\n",
    "mode = Mode.FULL_BODY\n",
    "dataset_train.mode = mode\n",
    "rgb, depth, pose_2d, gt, session = dataset_train[i]\n",
    "dataset_train.frame.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "Now that the data is loaded we can analyse it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Type', 'Session', 'Difficulty', 'Exercise', 'Frame', 'Joint', 'Error', 'mode']\n",
    "df_data = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in tqdm(range(len(dataset_train))):\n",
    "  for m in [Mode.FULL_BODY, Mode.HALF_BODY, Mode.LIMBS, Mode.JOINTS]:\n",
    "    dataset_train.mode = m\n",
    "    rgb, depth, pose_2d, gt, session = dataset_train[i]\n",
    "\n",
    "    gt = gt2err(gt, m)[0]\n",
    "    session, frame_i = dataset_train.get_index(i)\n",
    "    frame = dataset_train.frame\n",
    "    session_name = frame.session[\"Name\"]\n",
    "    exercise = frame.session['Session Parameters']['Exercise']\n",
    "    difficulty = int(exercise[2])\n",
    "\n",
    "    for j, err in enumerate(gt):\n",
    "      row = [\"Train\", session_name, difficulty, exercise, frame_i, j, int(err), m]\n",
    "      df_data.loc[len(df_data)] = row\n",
    "\n",
    "for i in tqdm(range(len(dataset_test))):\n",
    "  for m in [Mode.FULL_BODY, Mode.HALF_BODY, Mode.LIMBS, Mode.JOINTS]:\n",
    "    dataset_test.mode = m\n",
    "    _, _, _, gt, _ = dataset_test[i]\n",
    "    gt = gt2err(gt, m)[0]\n",
    "    session, frame_i = dataset_test.get_index(i)\n",
    "    frame = dataset_test.frame\n",
    "    session_name = frame.session[\"Name\"]\n",
    "    exercise = frame.session['Session Parameters']['Exercise']\n",
    "    difficulty = int(exercise[2])\n",
    "\n",
    "    for j, err in enumerate(gt):\n",
    "      row = [\"Test\", session_name, difficulty, exercise, frame_i, j, int(err), m]\n",
    "      df_data.loc[len(df_data)] = row\n",
    "\n",
    "dataset_train.mode = mode\n",
    "dataset_test.mode = mode\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_joints    = df_data[df_data['mode'] == Mode.JOINTS]\n",
    "df_data_limbs     = df_data[df_data['mode'] == Mode.LIMBS]\n",
    "df_data_half_body = df_data[df_data['mode'] == Mode.HALF_BODY]\n",
    "df_data_full_body = df_data[df_data['mode'] == Mode.FULL_BODY]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Distribution Per Joint\n",
    "\n",
    "Here we investigate the distribution of errors based on Body regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_joints[\"pose_id\"]      = df_data_joints[\"Session\"] + \"_\" + df_data_joints[\"Frame\"].astype(str)\n",
    "df_data_joints[\"error_simple\"] = df_data_joints[\"Error\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "df_data_joints[\"joint_name\"]   = df_data_joints[\"Joint\"].apply(lambda x: joint_names[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict_halves = Mode.HALF_BODY.get_class_dict()\n",
    "df_data_joints[\"Upper Body\"] = df_data_joints[\"Joint\"].apply(lambda x: x in class_dict_halves[\"Upper Body\"])\n",
    "df_data_joints[\"Lower Body\"] = df_data_joints[\"Joint\"].apply(lambda x: x in class_dict_halves[\"Lower Body\"])\n",
    "\n",
    "class_dict_limbs = Mode.LIMBS.get_class_dict()\n",
    "df_data_joints[\"Torso\"]     = df_data_joints[\"Joint\"].apply(lambda x: x in class_dict_limbs[\"Torso\"])\n",
    "df_data_joints[\"Head\"]      = df_data_joints[\"Joint\"].apply(lambda x: x in class_dict_limbs[\"Head\"])\n",
    "df_data_joints[\"Left Arm\"]  = df_data_joints[\"Joint\"].apply(lambda x: x in class_dict_limbs[\"Left Arm\"])\n",
    "df_data_joints[\"Right Arm\"] = df_data_joints[\"Joint\"].apply(lambda x: x in class_dict_limbs[\"Right Arm\"])\n",
    "df_data_joints[\"Left Leg\"]  = df_data_joints[\"Joint\"].apply(lambda x: x in class_dict_limbs[\"Left Leg\"])\n",
    "df_data_joints[\"Right Leg\"] = df_data_joints[\"Joint\"].apply(lambda x: x in class_dict_limbs[\"Right Leg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_joints[\"body_half\"] = df_data_joints[\"Joint\"].apply(lambda x: Mode.HALF_BODY.get_class(x))\n",
    "df_data_joints[\"body_part\"] = df_data_joints[\"Joint\"].apply(lambda x: Mode.LIMBS.get_class(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (6, 4))\n",
    "error_distr = df_data_joints.groupby(\"pose_id\")[\"error_simple\"].sum().reset_index()[\"error_simple\"]\n",
    "error_distr = error_distr[error_distr > 0]\n",
    "error_distr.plot.hist(bins = range(1, 20), density=True)\n",
    "error_distr.plot(kind = \"kde\", alpha = 0.7)\n",
    "quant = error_distr.quantile(0.7)\n",
    "ax.axvline(quant, color=\"red\", alpha = .7, ymax = 1, linestyle = \":\")\n",
    "ax.set_title(\"Distribution of number of joints with error per pose\")\n",
    "ax.set_xlabel(\"Number of Joints with Error\")\n",
    "ax.set_ylabel(\"Number of poses\")\n",
    "ax.set_xlim(1, 20)\n",
    "ax.set_xticks([1, 5, 10, 15, 20])\n",
    "ax.set_yticks([])\n",
    "plt.savefig(\"figures/distribution_of_joint_errors_per_pose.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize = (10,4), nrows=1, ncols=2)\n",
    "\n",
    "err_dist_upper = df_data_joints[df_data_joints[\"body_half\"] == \"Upper Body\"][df_data_joints[\"error_simple\"] == 1].groupby(\"pose_id\")[\"error_simple\"].sum().reset_index()[\"error_simple\"]\n",
    "err_dist_lower = df_data_joints[df_data_joints[\"body_half\"] == \"Lower Body\"].groupby(\"pose_id\")[\"error_simple\"].sum().reset_index()[\"error_simple\"]\n",
    "\n",
    "err_dist_upper = err_dist_upper[err_dist_upper > 0]\n",
    "err_dist_lower = err_dist_lower[err_dist_lower > 0]\n",
    "\n",
    "err_dist_upper.plot.hist(bins = range(1, 16), density=True, ax = axs[0])\n",
    "err_dist_upper.plot(kind = \"kde\", ax = axs[0])\n",
    "\n",
    "err_dist_lower.plot.hist(bins = range(1, 11), density=True, ax = axs[1])\n",
    "err_dist_lower.plot(kind = \"kde\", ax = axs[1])\n",
    "\n",
    "fig.suptitle(\"Distribution of number of joints with error per pose per body half\")\n",
    "axs[0].set_title(\"Upper Body\")\n",
    "axs[1].set_title(\"Lower Body\")\n",
    "\n",
    "axs[0].set_xlim(1, 15)\n",
    "axs[0].set_xticks([1, 5, 10, 15])\n",
    "axs[1].set_xlim(1, 10)\n",
    "axs[1].set_xticks([1, 5, 10])\n",
    "\n",
    "quant = err_dist_upper.quantile(0.7)\n",
    "axs[0].axvline(quant, color=\"red\", alpha = .7, ymax = 1, linestyle = \":\")\n",
    "\n",
    "quant = err_dist_lower.quantile(0.7)\n",
    "axs[1].axvline(quant, color=\"red\", alpha = .7, ymax = 1, linestyle = \":\")\n",
    "\n",
    "\n",
    "for ax in axs:\n",
    "  ax.set_ylabel(\"Number of Errors\")\n",
    "  ax.set_xlabel(\"Number of Joints\")\n",
    "  ax.set_yticks([])\n",
    "\n",
    "plt.savefig(\"figures/distribution_of_joint_errors_per_pose_per_body_half.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize = (6,8), nrows=3, ncols=2)\n",
    "\n",
    "def plot_error_distribution(df, body_part, thresh_dict, ax):\n",
    "  err_dist = df[df[\"body_part\"] == body_part].groupby(\"pose_id\")[\"error_simple\"].sum().reset_index()[\"error_simple\"]\n",
    "  err_dist = err_dist[err_dist > 0]\n",
    "\n",
    "  err_dist.plot.hist(bins = range(1, 11), density=True, ax = ax)\n",
    "  err_dist.plot(kind = \"kde\", ax = ax)\n",
    "\n",
    "  ax.set_title(body_part)\n",
    "\n",
    "  quant = err_dist.quantile(0.7)\n",
    "  thresh_dict[body_part] = quant\n",
    "  ax.axvline(quant, color=\"red\", alpha = .7, ymax = 1, linestyle = \":\")\n",
    "\n",
    "  ax.set_xlim(1, 5)\n",
    "  ax.set_xticks([1, 2, 3, 4, 5])\n",
    "  ax.set_yticks([])\n",
    "\n",
    "\n",
    "thresh_dict = {}\n",
    "\n",
    "plot_error_distribution(df_data_joints, \"Torso\",      thresh_dict, axs[0,0])\n",
    "plot_error_distribution(df_data_joints, \"Head\",       thresh_dict, axs[0,1])\n",
    "plot_error_distribution(df_data_joints, \"Left Arm\",   thresh_dict, axs[1,0])\n",
    "plot_error_distribution(df_data_joints, \"Right Arm\",  thresh_dict, axs[1,1])\n",
    "plot_error_distribution(df_data_joints, \"Left Leg\",   thresh_dict, axs[2,0])\n",
    "plot_error_distribution(df_data_joints, \"Right Leg\",  thresh_dict, axs[2,1])\n",
    "\n",
    "for ax in axs:\n",
    "  ax[0].set_ylabel(\"Number of Errors\")\n",
    "  ax[1].set_ylabel(\"\")\n",
    "  \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/distribution_of_joint_errors_per_pose_per_body_part.png\")\n",
    "plt.show()\n",
    "\n",
    "print(thresh_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Distribution\n",
    "\n",
    "Here we investigate the distribution of errors over the dataset for different body regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_joints[\"Joint Name\"] = df_data_joints[\"Joint\"].apply(lambda x: joint_names[x])\n",
    "df_data_joints[\"Simple Error\"] = df_data_joints[\"Error\"] != 0\n",
    "df_data_joints[\"Difficulty Name\"] = df_data_joints[\"Difficulty\"].apply(lambda x: \"Trivial\" if x == 0 else \"Easy\" if x == 1 else \"Medium\" if x == 2 else \"Hard\")\n",
    "df_data_joints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_data_joints[[\"Error\", \"Frame\"]].groupby(\"Error\").count().plot.pie(subplots=True, figsize=(4, 4), title=\"Error Distribution\", labels=joint_errors, autopct='%1.1f%%', pctdistance=1.25, fontsize=12, explode=(.1,.1,.1,.1), labeldistance=None)\n",
    "\n",
    "ax[0].set_ylabel(\"\")\n",
    "ax[0].legend(bbox_to_anchor=(1, 1.02), loc='center left')\n",
    "\n",
    "plt.savefig(\"figures/dist_joints/Error_Distribution.png\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_by_difficulty = df_data_joints[['Difficulty', \"Difficulty Name\", \"Simple Error\"]].groupby([\"Difficulty Name\"]).mean().sort_values(by=\"Difficulty\")[\"Simple Error\"]\n",
    "ax = error_by_difficulty.plot.bar()\n",
    "ax.set_ylabel(\"Error Rate\")\n",
    "ax.set_xlabel(\"Difficulty\")\n",
    "ax.set_title(\"Error Rate by Difficulty\")\n",
    "ax.set_ylim(0, 1)\n",
    "labels = ['Trivial', 'Easy', 'Medium', 'Hard']\n",
    "ax.set_xticks([0, 1, 2, 3])\n",
    "ax.set_xticklabels(labels, rotation=0, ha='center')\n",
    "plt.savefig(\"figures/dist_joints/Error_Rate_by_Difficulty.png\")\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_group = df_data_joints[['Difficulty', \"Difficulty Name\", \"Error\"]].groupby([\"Difficulty Name\", \"Error\"]).count()[\"Difficulty\"].unstack().T\n",
    "error_distribution_by_difficulty = (err_group / err_group.sum()).T\n",
    "error_distribution_by_difficulty['sort_key'] = pd.CategoricalIndex(error_distribution_by_difficulty, [3, 0, 2, 1])\n",
    "error_distribution_by_difficulty.sort_values('sort_key', inplace=True)\n",
    "error_distribution_by_difficulty.drop('sort_key', axis=1, inplace=True)\n",
    "\n",
    "axs = error_distribution_by_difficulty.T.plot.pie(subplots=True, figsize=(10, 10), layout=(2, 2), legend=False, title=\"Error Distribution by Difficulty\", labels=joint_errors, autopct='%1.1f%%', pctdistance=1.25, fontsize=12, explode=(.1,.1,.1,.1), sharex=False, sharey=False, labeldistance=None)\n",
    "\n",
    "axs[0, 0].set_xlabel(\"Trivial\")\n",
    "axs[0, 0].set_ylabel(\"\")\n",
    "axs[0, 1].set_xlabel(\"Easy\")\n",
    "axs[0, 1].set_ylabel(\"\")\n",
    "axs[0, 1].legend(bbox_to_anchor=(1, 1.02), loc='center left')\n",
    "axs[1, 0].set_xlabel(\"Medium\")\n",
    "axs[1, 0].set_ylabel(\"\")\n",
    "axs[1, 1].set_xlabel(\"Hard\")\n",
    "axs[1, 1].set_ylabel(\"\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/dist_joints/Error_Distribution_by_Difficulty.png\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df_data_joints[[\"Joint\", \"Simple Error\"]].groupby([\"Joint\"]).sum()\n",
    "s[\"Sorted Names\"] = joint_names\n",
    "s = s.sort_values(by=\"Simple Error\", ascending=False)\n",
    "\n",
    "err_joints = df_data_joints[[\"Joint\", \"Joint Name\", \"Error\"]]\n",
    "error_distribution_by_joint = err_joints.groupby([\"Joint\", \"Error\"]).count().unstack().reindex(s.index).T\n",
    "\n",
    "error_distribution_by_joint = (error_distribution_by_joint / error_distribution_by_joint.sum()).T.fillna(0)\n",
    "error_distribution_by_joint.columns = error_distribution_by_joint.columns.droplevel()\n",
    "\n",
    "error_distribution_by_joint.index = s[\"Sorted Names\"].tolist()\n",
    "\n",
    "edj = error_distribution_by_joint.T\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "axs = edj.plot.pie(ax=ax1, subplots=True, figsize=(10, 10), layout=(4, 5), legend=False, title=\"Error Distribution by Joint\", fontsize=12, sharex=False, sharey=False, labeldistance=None, explode=(.05,.05,.05,.1))\n",
    "\n",
    "for ax in axs.flatten():\n",
    "  ax.set_xlabel(ax.get_ylabel())\n",
    "  ax.set_ylabel(\"\")\n",
    "\n",
    "plt.legend(joint_errors, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "ax1.set_title(\"Error Distribution by Joint\")\n",
    "plt.savefig(\"figures/dist_joints/Error_Distribution_by_Joint.png\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_full_body[\"Joint Name\"] = df_data_full_body[\"Joint\"].apply(lambda x: joint_names[x])\n",
    "df_data_full_body[\"Difficulty Name\"] = df_data_full_body[\"Difficulty\"].apply(lambda x: \"Trivial\" if x == 0 else \"Easy\" if x == 1 else \"Medium\" if x == 2 else \"Hard\")\n",
    "df_data_full_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_by_difficulty = df_data_full_body[['Difficulty', \"Difficulty Name\", \"Error\"]].groupby([\"Difficulty Name\"]).mean().sort_values(by=\"Difficulty\")[\"Error\"]\n",
    "ax = error_by_difficulty.plot.bar()\n",
    "ax.set_ylabel(\"Error Rate\")\n",
    "ax.set_xlabel(\"Difficulty\")\n",
    "ax.set_title(\"Error Rate by Difficulty\")\n",
    "ax.set_ylim(0, 1)\n",
    "labels = ['Trivial', 'Easy', 'Medium', 'Hard']\n",
    "ax.set_xticks([0, 1, 2, 3])\n",
    "ax.set_xticklabels(labels, rotation=0, ha='center')\n",
    "plt.savefig(\"figures/dist_full_body/Error_Rate_by_Difficulty.png\")\n",
    "ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Body Halves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_half_body[\"Joint Name\"] = df_data_half_body[\"Joint\"].apply(lambda x: body_halves[x])\n",
    "df_data_half_body[\"Difficulty Name\"] = df_data_half_body[\"Difficulty\"].apply(lambda x: \"Trivial\" if x == 0 else \"Easy\" if x == 1 else \"Medium\" if x == 2 else \"Hard\")\n",
    "#df_data_half_body[\"Error\"] = df_data_half_body[[\"Joint Name\", \"Error\"]].apply(lambda x: x[\"Joint Name\"] if x[\"Error\"] == 1 else \"No Error\", axis=1)\n",
    "df_data_half_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_by_difficulty = df_data_half_body[['Difficulty', \"Difficulty Name\", \"Error\"]].groupby([\"Difficulty Name\"]).mean().sort_values(by=\"Difficulty\")[\"Error\"]\n",
    "ax = error_by_difficulty.plot.bar()\n",
    "ax.set_ylabel(\"Error Rate\")\n",
    "ax.set_xlabel(\"Difficulty\")\n",
    "ax.set_title(\"Error Rate by Difficulty\")\n",
    "ax.set_ylim(0, 1)\n",
    "labels = ['Trivial', 'Easy', 'Medium', 'Hard']\n",
    "ax.set_xticks([0, 1, 2, 3])\n",
    "ax.set_xticklabels(labels, rotation=0, ha='center')\n",
    "plt.savefig(\"figures/dist_half_body/Error_Rate_by_Difficulty.png\")\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df_data_half_body[[\"Joint\", \"Error\"]].groupby([\"Joint\"]).sum()\n",
    "s[\"Sorted Names\"] = body_halves\n",
    "s = s.sort_values(by=\"Error\", ascending=False)\n",
    "\n",
    "err_joints = df_data_half_body[[\"Joint\", \"Joint Name\", \"Error\"]]\n",
    "error_distribution_by_joint = err_joints.groupby([\"Joint\", \"Error\"]).count().unstack().reindex(s.index).T\n",
    "\n",
    "error_distribution_by_joint = (error_distribution_by_joint / error_distribution_by_joint.sum()).T.fillna(0)\n",
    "error_distribution_by_joint.columns = error_distribution_by_joint.columns.droplevel()\n",
    "\n",
    "error_distribution_by_joint.index = s[\"Sorted Names\"].tolist()\n",
    "\n",
    "edj = error_distribution_by_joint.T\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "axs = edj.plot.pie(ax=ax1, subplots=True, layout=(1, 2), legend=False, title=\"Error Distribution by Joint\", fontsize=12, sharex=False, sharey=False, labeldistance=None, explode=(.05,.1), autopct='%1.1f%%', pctdistance=1.25)\n",
    "\n",
    "for ax in axs.flatten():\n",
    "  ax.set_xlabel(ax.get_ylabel())\n",
    "  ax.set_ylabel(\"\")\n",
    "\n",
    "plt.legend([\"No Error\", \"Error\"], loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "ax1.set_title(\"Error Distribution by Joint\")\n",
    "plt.savefig(\"figures/dist_half_body/Error_Distribution_by_Joint.png\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_limbs[\"Joint Name\"] = df_data_limbs[\"Joint\"].apply(lambda x: limbs[x])\n",
    "df_data_limbs[\"Difficulty Name\"] = df_data_limbs[\"Difficulty\"].apply(lambda x: \"Trivial\" if x == 0 else \"Easy\" if x == 1 else \"Medium\" if x == 2 else \"Hard\")\n",
    "df_data_limbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_by_difficulty = df_data_limbs[['Difficulty', \"Difficulty Name\", \"Error\"]].groupby([\"Difficulty Name\"]).mean().sort_values(by=\"Difficulty\")[\"Error\"]\n",
    "ax = error_by_difficulty.plot.bar()\n",
    "ax.set_ylabel(\"Error Rate\")\n",
    "ax.set_xlabel(\"Difficulty\")\n",
    "ax.set_title(\"Error Rate by Difficulty\")\n",
    "ax.set_ylim(0, 1)\n",
    "labels = ['Trivial', 'Easy', 'Medium', 'Hard']\n",
    "ax.set_xticks([0, 1, 2, 3])\n",
    "ax.set_xticklabels(labels, rotation=0, ha='center')\n",
    "plt.savefig(\"figures/dist_limbs/Error_Rate_by_Difficulty.png\")\n",
    "ax"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
