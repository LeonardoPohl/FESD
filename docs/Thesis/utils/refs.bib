@article{euler1776formulae,
  author  = {Euler, Leonhard},
  journal = {Novi Commentarii academiae scientiarum Petropolitanae},
  title   = {Formulae generales pro translatione quacunque corporum rigidorum},
  year    = {1776},
  pages   = {189--207},
  ranking = {rank2},
}

@Misc{IterativeErrorFeedback,
  author    = {Carreira, Joao and Agrawal, Pulkit and Fragkiadaki, Katerina and Malik, Jitendra},
  title     = {Human Pose Estimation with Iterative Error Feedback},
  year      = {2015},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.1507.06550},
  file      = {:IterativeErrorFeedback - Human Pose Estimation with Iterative Error Feedback.pdf:PDF},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
  url       = {https://arxiv.org/abs/1507.06550},
}

@article{h36m_pami,
  author    = {Ionescu, Catalin and Papava, Dragos and Olaru, Vlad and Sminchisescu, Cristian},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title     = {Human3.6M: Large Scale Datasets and Predictive Methods for 3D Human Sensing in Natural Environments},
  year      = {2014},
  month     = {jul},
  number    = {7},
  pages     = {1325-1339},
  volume    = {36},
  publisher = {IEEE Computer Society},
}

@InProceedings{IonescuSminchisescu11,
  author    = {Catalin Ionescu, Fuxin Li, Cristian Sminchisescu},
  booktitle = {International Conference on Computer Vision},
  title     = {Latent Structured Models for Human Pose Estimation},
  year      = {2011},
  file      = {:IonescuSminchisescu11 - Latent Structured Models for Human Pose Estimation.pdf:PDF},
}

@article{PASCUALHERNANDEZ2022102225,
  author   = {David Pascual-Hernández and Nuria {Oyaga de Frutos} and Inmaculada Mora-Jiménez and José María Cañas-Plaza},
  journal  = {Displays},
  title    = {Efficient 3D human pose estimation from RGBD sensors},
  year     = {2022},
  issn     = {0141-9382},
  pages    = {102225},
  volume   = {74},
  abstract = {Human pose estimation is a core component in applications for which some level of human–computer interaction is required, such as assistive robotics, ambient assisted living or the motion capture systems used in biomechanics or video games production. In this paper, we propose an end-to-end pipeline for estimating 3D human poses that works in real-time in an off-the-shelf computer, using as input video sequences captured with a commercial RGBD sensor. Our hybrid approach is composed of two stages: 2D pose estimation using deep neural networks and 3D registration, for which a lightweight algorithm based on classic computer vision techniques has been developed. We compare several 2D pose estimators and validate the performance of our proposed method against the state-of-the-art, using as benchmark an international and publicly available dataset. Our 2D to 3D registration module alone can reach frame rates of up to 99 fps, while achieving an average error per joint of 132 mm. Furthermore, the proposed solution is agnostic to the model used for 2D pose estimation and can be upgraded with new upcoming solutions or adapted for different articulated objects.},
  doi      = {https://doi.org/10.1016/j.displa.2022.102225},
  keywords = {Computer vision, Human pose estimation, RGBD sensors, Human–computer interaction},
  url      = {https://www.sciencedirect.com/science/article/pii/S0141938222000579},
}

@misc{TensorflowRealsense, 
  author       = {Intel},
  howpublished = {\url{https://dev.intelrealsense.com/docs/tensorflow-with-intel-realsense-cameras}},
  note         = {Accessed: 18-02-2023},
  title        = {Tensorflow with Intel Realsense camera},
  journal      = {Intel® RealSense™ Developer Documentation},
  publisher    = {Intel},
}

@Misc{UNET,
  author    = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  title     = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
  year      = {2015},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.1505.04597},
  file      = {:UNET - U Net_ Convolutional Networks for Biomedical Image Segmentation.pdf:PDF},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
  url       = {https://arxiv.org/abs/1505.04597},
}

@InProceedings{OpenPoseHand,
  author    = {Tomas Simon and Hanbyul Joo and Iain Matthews and Yaser Sheikh},
  booktitle = {CVPR},
  title     = {Hand Keypoint Detection in Single Images using Multiview Bootstrapping},
  year      = {2017},
  file      = {:OpenPoseHand - Hand Keypoint Detection in Single Images Using Multiview Bootstrapping.pdf:PDF},
}

@InProceedings{OpenPoseMulti,
  author    = {Zhe Cao and Tomas Simon and Shih-En Wei and Yaser Sheikh},
  booktitle = {CVPR},
  title     = {Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields},
  year      = {2017},
  file      = {:OpenPoseMulti - Realtime Multi Person 2D Pose Estimation Using Part Affinity Fields.pdf:PDF},
}

@InProceedings{OpenPoseCnn,
  author    = {Shih-En Wei and Varun Ramakrishna and Takeo Kanade and Yaser Sheikh},
  booktitle = {CVPR},
  title     = {Convolutional pose machines},
  year      = {2016},
  file      = {:OpenPoseCnn - Convolutional Pose Machines.pdf:PDF},
}

@misc{ONNX,
  author       = {Bai, Junjie and Lu, Fang and Zhang, Ke and others},
  howpublished = {\url{https://github.com/onnx/onnx}},
  title        = {ONNX: Open Neural Network Exchange},
  year         = {2019},
  journal      = {GitHub repository},
  publisher    = {GitHub},
}

@Misc{RGBDHPEforRoboticTaskLearning,
  author    = {Zimmermann, Christian and Welschehold, Tim and Dornhege, Christian and Burgard, Wolfram and Brox, Thomas},
  title     = {3D Human Pose Estimation in RGBD Images for Robotic Task Learning},
  year      = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.1803.02622},
  file      = {:RGBDHPEforRoboticTaskLearning - 3D Human Pose Estimation in RGBD Images for Robotic Task Learning.pdf:PDF},
  groups    = {RGBD},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
  url       = {https://arxiv.org/abs/1803.02622},
}

@InProceedings{EarlyRGBDHPE,
  author    = {Shotton, Jamie and Fitzgibbon, Andrew and Cook, Mat and Sharp, Toby and Finocchio, Mark and Moore, Richard and Kipman, Alex and Blake, Andrew},
  booktitle = {CVPR 2011},
  title     = {Real-time human pose recognition in parts from single depth images},
  year      = {2011},
  pages     = {1297-1304},
  doi       = {10.1109/CVPR.2011.5995316},
  file      = {:EarlyRGBDHPE - Real Time Human Pose Recognition in Parts from Single Depth Images.pdf:PDF},
}

@Article{OldCNN,
  author  = {Kunihiko Fukushima},
  journal = {Neural Networks},
  title   = {Neocognitron: A hierarchical neural network capable of visual pattern recognition},
  year    = {1988},
  issn    = {0893-6080},
  number  = {2},
  pages   = {119-130},
  volume  = {1},
  doi     = {https://doi.org/10.1016/0893-6080(88)90014-7},
  file    = {:OldCNN - Neocognitron_ a Hierarchical Neural Network Capable of Visual Pattern Recognition.pdf:PDF},
  url     = {https://www.sciencedirect.com/science/article/pii/0893608088900147},
}

@InProceedings{AlexNet,
  author    = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {ImageNet Classification with Deep Convolutional Neural Networks},
  year      = {2012},
  editor    = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
  publisher = {Curran Associates, Inc.},
  volume    = {25},
  file      = {:AlexNet - ImageNet Classification with Deep Convolutional Neural Networks (1).pdf:PDF;:AlexNet - ImageNet Classification with Deep Convolutional Neural Networks.pdf:PDF},
  url       = {https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
}

@Misc{VGG,
  author    = {Simonyan, Karen and Zisserman, Andrew},
  title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  year      = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.1409.1556},
  file      = {:VGG - Very Deep Convolutional Networks for Large Scale Image Recognition.pdf:PDF},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
  url       = {https://arxiv.org/abs/1409.1556},
}

@Article{HPEIsHard,
  author  = {Tölgyessy, Michal and Dekan, Martin and Chovanec, Lubos},
  journal = {Applied Sciences},
  title   = {Skeleton Tracking Accuracy and Precision Evaluation of Kinect V1, Kinect V2, and the Azure Kinect},
  year    = {2021},
  month   = {06},
  pages   = {5756},
  volume  = {11},
  doi     = {10.3390/app11125756},
  file    = {:HPEIsHard - Skeleton Tracking Accuracy and Precision Evaluation of Kinect V1, Kinect V2, and the Azure Kinect.pdf:PDF},
}

@InProceedings{RGBDHPE,
  author    = {Haggag, H. and Hossny, M. and Nahavandi, S. and Haggag, O.},
  booktitle = {2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
  title     = {An adaptable system for RGB-D based human body detection and pose estimation: Incorporating attached props},
  year      = {2016},
  pages     = {001544-001549},
  doi       = {10.1109/SMC.2016.7844458},
  groups    = {RGBD},
}

@Article{ElboushakiAbdessamad2020MAmf,
  author    = {Elboushaki, Abdessamad and Hannane, Rachida and Afdel, Karim and Koutti, Lahcen},
  journal   = {Expert systems with applications},
  title     = {MultiD-CNN: A multi-dimensional feature learning approach based on deep convolutional networks for gesture recognition in RGB-D image sequences},
  year      = {2020},
  issn      = {0957-4174},
  pages     = {112829},
  volume    = {139},
  address   = {New York},
  copyright = {2019 Elsevier Ltd},
  file      = {:ElboushakiAbdessamad2020MAmf - MultiD CNN_ a Multi Dimensional Feature Learning Approach Based on Deep Convolutional Networks for Gesture Recognition in RGB D Image Sequences.pdf:PDF},
  groups    = {RGBD},
  keywords  = {Artificial neural networks ; Computer architecture ; Computer vision ; Convolutional neural networks ; Deep learning ; Embedded systems ; Expert systems ; Feature extraction ; Feature fusion ; Gesture recognition ; Human-computer interface ; Machine learning ; Multimodal learning ; Object recognition ; Occlusion ; Performance evaluation ; Representations ; RGB-D video processing ; Robotics ; Sequences ; Video data},
  language  = {eng},
  publisher = {Elsevier Ltd},
}

@Article{Chen2021,
  author    = {Chen, Qian and Liu, Ze and Zhang, Yi and Fu, Keren and Zhao, Qijun and Du, Hongwei},
  title     = {RGB-D Salient Object Detection via 3D Convolutional Neural Networks},
  year      = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.2101.10241},
  file      = {:Chen2021 - RGB D Salient Object Detection Via 3D Convolutional Neural Networks.pdf:PDF;:Chen2021 - RGB D Salient Object Detection Via 3D Convolutional Neural Networks.pdf:PDF},
  groups    = {RGBD},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
  url       = {https://arxiv.org/abs/2101.10241},
}

@Article{NeiliBoualia2021,
  author  = {Neili Boualia, Sameh and ESSOUKRI BEN AMARA, Najoua},
  journal = {Informatics},
  title   = {Deep Full-Body HPE for Activity Recognition from RGB Frames Only},
  year    = {2021},
  month   = {01},
  pages   = {2},
  volume  = {8},
  doi     = {10.3390/informatics8010002},
  file    = {:NeiliBoualia2021 - Deep Full Body HPE for Activity Recognition from RGB Frames Only.pdf:PDF;:NeiliBoualia2021 - Deep Full Body HPE for Activity Recognition from RGB Frames Only.pdf:PDF},
}

@Article{Seddik2017,
  author   = {Seddik, Bassem and Gazzah, Sami and Essoukri Ben Amara, Najoua},
  journal  = {IET Computer Vision},
  title    = {Human-action recognition using a multi-layered fusion scheme of Kinect modalities},
  year     = {2017},
  number   = {7},
  pages    = {530-540},
  volume   = {11},
  doi      = {https://doi.org/10.1049/iet-cvi.2016.0326},
  eprint   = {https://ietresearch.onlinelibrary.wiley.com/doi/pdf/10.1049/iet-cvi.2016.0326},
  keywords = {image recognition, image sensors, support vector machines, image representation, human-action recognition, multilayered fusion scheme, Kinect modalities, RGB, depth modalities, global SVM models, local SVM models, local descriptor performance, global bags-of-visual-words representations, Fisher vector representation concatenation, iterative scores fusion, CGC-2014, CAD-60},
  url      = {https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/iet-cvi.2016.0326},
}

@Article{OpenPosePose,
  author  = {Z. {Cao} and G. {Hidalgo Martinez} and T. {Simon} and S. {Wei} and Y. A. {Sheikh}},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title   = {OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields},
  year    = {2019},
  file    = {:OpenPosePose - OpenPose_ Realtime Multi Person 2D Pose Estimation Using Part Affinity Fields.pdf:PDF},
}

@Article{ReviewPointcloudHPE,
  author  = {Xu, Tianxu and An, Dong and Jia, Yuetong and Yue, Yang},
  journal = {Sensors},
  title   = {A Review: Point Cloud-Based 3D Human Joints Estimation},
  year    = {2021},
  month   = {03},
  pages   = {1684},
  volume  = {21},
  doi     = {10.3390/s21051684},
  file    = {:ReviewPointcloudHPE - A Review_ Point Cloud Based 3D Human Joints Estimation.pdf:PDF},
  groups  = {Reviews},
}

@Article{ReviewHPE,
  author  = {Dubey, Shradha and Dixit, Manish},
  journal = {Multimedia Systems},
  title   = {A comprehensive survey on human pose estimation approaches},
  year    = {2022},
  month   = {08},
  volume  = {29},
  doi     = {10.1007/s00530-022-00980-0},
  file    = {:papers/Survey_HPE_RGB.pdf:PDF},
  groups  = {Reviews},
}

@Article{ReviewHPEforActionRecognition,
  author  = {Song, Liangchen and Yu, Gang and Yuan, Junsong and Liu, Zicheng},
  journal = {Journal of Visual Communication and Image Representation},
  title   = {Human pose estimation and its application to action recognition: A survey},
  year    = {2021},
  month   = {04},
  pages   = {103055},
  volume  = {76},
  doi     = {10.1016/j.jvcir.2021.103055},
  file    = {:ReviewHPEforActionRecognition - Human Pose Estimation and Its Application to Action Recognition_ a Survey.pdf:PDF},
  groups  = {Reviews},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: fileDirectory:H:\\FESD\\docs\\Thesis\\papers;}

@Comment{jabref-meta: fileDirectoryLatex-pohly-LEPO-PC:H:\\FESD\\docs\\Thesis;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:Reviews\;0\;0\;0x334db3ff\;\;\;;
1 StaticGroup:RGBD\;0\;1\;0x336633ff\;\;\;;
}

@Comment{jabref-meta: protectedFlag:true;}

@Comment{jabref-meta: saveActions:disabled;
all-text-fields[identity]
date[normalize_date]
month[normalize_month]
pages[normalize_page_numbers]
;}
