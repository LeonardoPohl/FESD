@article{euler1776formulae,
  title={Formulae generales pro translatione quacunque corporum rigidorum},
  author={Euler, Leonhard},
  journal={Novi Commentarii academiae scientiarum Petropolitanae},
  pages={189--207},
  year={1776}
}

@misc{IterativeErrorFeedback,
  doi = {10.48550/ARXIV.1507.06550},  
  url = {https://arxiv.org/abs/1507.06550},  
  author = {Carreira, Joao and Agrawal, Pulkit and Fragkiadaki, Katerina and Malik, Jitendra},  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), FOS: Computer and information sciences, FOS: Computer and information sciences},  
  title = {Human Pose Estimation with Iterative Error Feedback},  
  publisher = {arXiv},  
  year = {2015},  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{h36m_pami,
  author = {Ionescu, Catalin and Papava, Dragos and Olaru, Vlad and Sminchisescu,  Cristian},
  title = {Human3.6M: Large Scale Datasets and Predictive Methods for 3D Human Sensing in Natural Environments},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  publisher = {IEEE Computer Society},
  volume = {36},
  number = {7},
  pages = {1325-1339},
  month = {jul},
  year = {2014}
}

@inproceedings{IonescuSminchisescu11,
  author = {Catalin Ionescu, Fuxin Li, Cristian Sminchisescu},
  title = {Latent Structured Models for Human Pose Estimation},
  booktitle = {International Conference on Computer Vision},
  year = {2011}
}

@article{PASCUALHERNANDEZ2022102225,
  title = {Efficient 3D human pose estimation from RGBD sensors},
  journal = {Displays},
  volume = {74},
  pages = {102225},
  year = {2022},
  issn = {0141-9382},
  doi = {https://doi.org/10.1016/j.displa.2022.102225},
  url = {https://www.sciencedirect.com/science/article/pii/S0141938222000579},
  author = {David Pascual-Hernández and Nuria {Oyaga de Frutos} and Inmaculada Mora-Jiménez and José María Cañas-Plaza},
  keywords = {Computer vision, Human pose estimation, RGBD sensors, Human–computer interaction},
  abstract = {Human pose estimation is a core component in applications for which some level of human–computer interaction is required, such as assistive robotics, ambient assisted living or the motion capture systems used in biomechanics or video games production. In this paper, we propose an end-to-end pipeline for estimating 3D human poses that works in real-time in an off-the-shelf computer, using as input video sequences captured with a commercial RGBD sensor. Our hybrid approach is composed of two stages: 2D pose estimation using deep neural networks and 3D registration, for which a lightweight algorithm based on classic computer vision techniques has been developed. We compare several 2D pose estimators and validate the performance of our proposed method against the state-of-the-art, using as benchmark an international and publicly available dataset. Our 2D to 3D registration module alone can reach frame rates of up to 99 fps, while achieving an average error per joint of 132 mm. Furthermore, the proposed solution is agnostic to the model used for 2D pose estimation and can be upgraded with new upcoming solutions or adapted for different articulated objects.}
}

@article{ReviewPointcloudHPE,
  author = {Xu, Tianxu and An, Dong and Jia, Yuetong and Yue, Yang},
  year = {2021},
  month = {03},
  pages = {1684},
  title = {A Review: Point Cloud-Based 3D Human Joints Estimation},
  volume = {21},
  journal = {Sensors},
  doi = {10.3390/s21051684}
}

@article{ReviewHPE,
author = {Dubey, Shradha and Dixit, Manish},
year = {2022},
month = {08},
pages = {},
title = {A comprehensive survey on human pose estimation approaches},
volume = {29},
journal = {Multimedia Systems},
doi = {10.1007/s00530-022-00980-0}
}

@misc{TensorflowRealsense, 
  title={Tensorflow with Intel Realsense camera},
  howpublished={\url{https://dev.intelrealsense.com/docs/tensorflow-with-intel-realsense-cameras}},
  journal={Intel® RealSense™ Developer Documentation}, 
  publisher={Intel}, 
  author={Intel}, 
  note={Accessed: 18-02-2023}
} 

@misc{UNET,
  doi = {10.48550/ARXIV.1505.04597},
  url = {https://arxiv.org/abs/1505.04597},
  author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
  publisher = {arXiv},
  year = {2015},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{OPenPosePose,
  author = {Z. {Cao} and G. {Hidalgo Martinez} and T. {Simon} and S. {Wei} and Y. A. {Sheikh}},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title = {OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields},
  year = {2019}
}

@inproceedings{OpenPoseHand,
  author = {Tomas Simon and Hanbyul Joo and Iain Matthews and Yaser Sheikh},
  booktitle = {CVPR},
  title = {Hand Keypoint Detection in Single Images using Multiview Bootstrapping},
  year = {2017}
}

@inproceedings{OpenPoseMulti,
  author = {Zhe Cao and Tomas Simon and Shih-En Wei and Yaser Sheikh},
  booktitle = {CVPR},
  title = {Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields},
  year = {2017}
}

@inproceedings{OpenPoseCnn,
  author = {Shih-En Wei and Varun Ramakrishna and Takeo Kanade and Yaser Sheikh},
  booktitle = {CVPR},
  title = {Convolutional pose machines},
  year = {2016}
}

@misc{ONNX,
    author = {Bai, Junjie and Lu, Fang and Zhang, Ke and others},
    title = {ONNX: Open Neural Network Exchange},
    year = {2019},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/onnx/onnx}}
}

@article{ReviewHPEforActionRecognition,
author = {Song, Liangchen and Yu, Gang and Yuan, Junsong and Liu, Zicheng},
year = {2021},
month = {04},
pages = {103055},
title = {Human pose estimation and its application to action recognition: A survey},
volume = {76},
journal = {Journal of Visual Communication and Image Representation},
doi = {10.1016/j.jvcir.2021.103055}
}

@misc{RGBDHPEforRoboticTaskLearning,
  doi = {10.48550/ARXIV.1803.02622},
  url = {https://arxiv.org/abs/1803.02622},  
  author = {Zimmermann, Christian and Welschehold, Tim and Dornhege, Christian and Burgard, Wolfram and Brox, Thomas},  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences},  
  title = {3D Human Pose Estimation in RGBD Images for Robotic Task Learning},  
  publisher = {arXiv},  
  year = {2018},  
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@INPROCEEDINGS{EarlyRGBDHPE,
  author={Shotton, Jamie and Fitzgibbon, Andrew and Cook, Mat and Sharp, Toby and Finocchio, Mark and Moore, Richard and Kipman, Alex and Blake, Andrew},
  booktitle={CVPR 2011}, 
  title={Real-time human pose recognition in parts from single depth images}, 
  year={2011},
  volume={},
  number={},
  pages={1297-1304},
  doi={10.1109/CVPR.2011.5995316}
}

@article{OldCNN,
title = {Neocognitron: A hierarchical neural network capable of visual pattern recognition},
journal = {Neural Networks},
volume = {1},
number = {2},
pages = {119-130},
year = {1988},
issn = {0893-6080},
doi = {https://doi.org/10.1016/0893-6080(88)90014-7},
url = {https://www.sciencedirect.com/science/article/pii/0893608088900147},
author = {Kunihiko Fukushima}
}

@inproceedings{AlexNet,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}

@misc{VGG,
  doi = {10.48550/ARXIV.1409.1556},
  url = {https://arxiv.org/abs/1409.1556},
  author = {Simonyan, Karen and Zisserman, Andrew},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  publisher = {arXiv},
  year = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{HPEIsHard,
author = {Tölgyessy, Michal and Dekan, Martin and Chovanec, Lubos},
year = {2021},
month = {06},
pages = {5756},
title = {Skeleton Tracking Accuracy and Precision Evaluation of Kinect V1, Kinect V2, and the Azure Kinect},
volume = {11},
journal = {Applied Sciences},
doi = {10.3390/app11125756}
}

@INPROCEEDINGS{RGBDHPE,
  author={Haggag, H. and Hossny, M. and Nahavandi, S. and Haggag, O.},
  booktitle={2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={An adaptable system for RGB-D based human body detection and pose estimation: Incorporating attached props}, 
  year={2016},
  volume={},
  number={},
  pages={001544-001549},
  doi={10.1109/SMC.2016.7844458}
}

@article{ElboushakiAbdessamad2020MAmf,
issn = {0957-4174},
journal = {Expert systems with applications},
pages = {112829},
volume = {139},
publisher = {Elsevier Ltd},
year = {2020},
title = {MultiD-CNN: A multi-dimensional feature learning approach based on deep convolutional networks for gesture recognition in RGB-D image sequences},
copyright = {2019 Elsevier Ltd},
language = {eng},
address = {New York},
author = {Elboushaki, Abdessamad and Hannane, Rachida and Afdel, Karim and Koutti, Lahcen},
keywords = {Artificial neural networks ; Computer architecture ; Computer vision ; Convolutional neural networks ; Deep learning ; Embedded systems ; Expert systems ; Feature extraction ; Feature fusion ; Gesture recognition ; Human-computer interface ; Machine learning ; Multimodal learning ; Object recognition ; Occlusion ; Performance evaluation ; Representations ; RGB-D video processing ; Robotics ; Sequences ; Video data},
}

