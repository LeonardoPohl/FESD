\section{Data layout}

As mentioned earlier, the dataset is made up of multiple different modalities. There are two separate visual streams, the RGB stream, and the depth stream, as well as the estimated human pose, the relative time stamps of each frame, and the recording metadata. The recording metadata includes information about the camera, such as the horizontal as well as the vertical field of view, and the exercise. The exercise is captured as an Id and a separate file exists containing all exercises with a description.

The visual streams are normalised and combined into a single file. OpenCV is used to store the RGB and the depth data into a single matrix and after the stream into a single file per frame. The RGB data is normalised to have values between 0 and 1, whereas the depth data is stored in meters.

The pose that is estimated by Nuitrack, as well as the error labels, are stored in a separate JSON file. The separate frames are stored in a list of frames. Each frame contains a list of all people that were detected. Each person contains a list of joints as well as an error label, and an Id. Each joint is stored with real-world 3D coordinates which are stored in meters. These real-world coordinates are labelled $x$, $y$, and $z$. Additionally, the 2D projection and depth of the joint are stored in image coordinates and meters for the depth. The 2D projection is labelled $u$ and $v$ and the depth is labelled $d$. 

The error label is an integer which is the error id specific for joint and skeleton errors. The errors corresponding to the error ids are explained in section \ref{sec:data_labeling}.
