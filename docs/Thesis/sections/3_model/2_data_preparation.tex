\section{Data preparation}
\label{sec:data_preparation}

In previous sections we have explained the structure of the data and how the data is labeled. In this section we will explain how the data is prepared for training. The data preparation consists of two parts, data augmentation and data splitting.

After the data has been split and augmented, the data is stored in tensors of a fixed size. If an image is too small we apply a bilinear interpolation to resize the image. If an image is too large we crop the side. The images are resized to $300 \times 300$ pixels. The depth images are resized in the same way and area.

\subsection{Data augmentation}

To ensure that the model is robust to different variations in the data, the data is augmented. We apply three different forms of augmentation to the data. The first form of augmentation is flipping the data. The RGB image, the depth image and the relative joint coordinates are flipped horizontally. Furthermore, we apply random and non-random cropping to the visual data. We ensure that none of the joints are outside the image. We also apply random padding when the image is cropped. The final augmentation is gaussian noise. We apply gaussian noise to the RGB image and the depth image.

\subsection{Data splitting}

The data is split into three parts. The first part is the training data. The training data is used to train the model. The second part is the validation data. We split the training and the validation data vertically, i.e. we split the dataset along frames and not recording sessions. This is done to ensure that the validation data is comparable to the training data. 

The validation data is used to validate the model during training. The third part is the test data. The test data is used to test the model after training. The data is split into training data, validation data, and test data using the scikit-learn function \texttt{train\_test\_split}. The data is split into training data and validation data with a ratio of $0.7$ to $0.3$. The validation data is then split into validation data and test data with a ratio of $0.5$ to $0.5$. The data is split in this way to ensure that the validation data is always of the same size as the test data. This is done to ensure that the validation data is not biased towards certain classes. The validation data is not biased towards certain classes because the validation data is the same size as the test data. 

T