\section{Model training}
\label{sec:model_training}

To train a neural network with supervised learning, you first pass the input data into the network and forward it through the defined layers. Then a loss is calculated an is is back propagated through the network to adapt the weights accordingly. 

As mentioned earlier, error or anomaly detection for human pose estimation can be seen as a multi-class multi-object classification problem. The loss function needs to be chosen such that it best reflects the data and the efficacy of the model. In most classification problems \textit{Cross Entropy Loss} is calculated and propagated through the network to adapt the weights and convolutions accordingly. Cross entropy loss calculates the soft max of the result and compares it to the ground truth. The soft max calculates the probability of each index in a list based on the value at that index. Cross Entropy Loss penalises the results based on the probability of the target class.

However, since REPLACE_WE have multiple objects, in REPLACE_OUR case the different joints, REPLACE_WE have to slightly change the loss function. If REPLACE_WE were to use the Cross Entropy loss on the results as REPLACE_WE got them now, the model would try to optimise toward a single class for all joints, which does not correctly reflect the desired result. Therefore, REPLACE_WE apply the Cross Entropy loss on every joint and propagate them individually.

\textbf{Show formula of loss function}
